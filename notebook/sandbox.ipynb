{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler, SubsetRandomSampler\n",
    "from torchvision import models, transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.datasets.utils import check_integrity #, download_and_extract_archive\n",
    "import pandas\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.expanduser(\"~/few-shot-learning/\"))\n",
    "from few_shot.datasets import FashionProductImages, FashionProductImagesSmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((80,60), scale=(0.8, 1.0)),\n",
    "        # transforms.Resize((80,60)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((80,60)),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((80,60)),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "#datasets = {\n",
    "#    classes: {\n",
    "#        split: FashionProductImages(\n",
    "#            \"~/data\",\n",
    "#            split='train' if split in ['train', 'val'] else 'test',\n",
    "#            classes=classes,\n",
    "#            transform=data_transforms[split]\n",
    "#        ) for split in [\"train\", \"test\", \"val\"]\n",
    "#    } for classes in [\"top\", \"bottom\"]\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5505"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fashion = FashionProductImagesSmall(\"~/data\", classes=\"top\", split=\"train\", transform=data_transforms[\"train\"])\n",
    "fashion = FashionProductImages(\"~/data\", classes=\"bottom\", split=\"test\", transform=data_transforms[\"train\"])\n",
    "\n",
    "X, y = fashion[10]\n",
    "# X, y = fashion[10:15] # fails\n",
    "\n",
    "len(fashion)\n",
    "\n",
    "# 18000 + 15149 + 5787 + 5505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fashion)):\n",
    "    X, y = fashion[i]\n",
    "    # print(y.shape)\n",
    "    # if not isinstance(y, int):\n",
    "    #    import pdb; pdb.set_trace()\n",
    "    if not (X.shape[1]==80 and X.shape[2]==60):\n",
    "        import pdb; pdb.set_trace()\n",
    "\n",
    "counter = 0\n",
    "for (i, batch) in enumerate(train_loader):\n",
    "    counter += 64\n",
    "    print(counter)\n",
    "    # import pdb; pdb.set_trace()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_sample_count = np.bincount(fashion.target_indices, minlength=fashion.n_classes)\n",
    "print(class_sample_count)\n",
    "print(len(class_sample_count))\n",
    "print(sum(class_sample_count))\n",
    "\n",
    "print(np.unique(fashion.targets))\n",
    "print(len(np.unique(fashion.targets)))\n",
    "\n",
    "print(np.unique(fashion.df_meta[\"articleType\"]))\n",
    "print(len(np.unique(fashion.df_meta[\"articleType\"])))\n",
    "\n",
    "# all perfumes are from 2017, which means they're all in the test set\n",
    "fashion.df_meta[\n",
    "    (fashion.df_meta[\"articleType\"]==\"Perfume and Body Mist\")\n",
    "     & (fashion.df_meta[\"year\"] == 2017.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# train_size = int(len(fashion) * 0.9)\n",
    "# trainset, valset = random_split(fashion, [train_size, len(fashion) - train_size])\n",
    "trainset = datasets['top']['train']\n",
    "valset = datasets['top']['val']\n",
    "\n",
    "train_sampler, train_indices, val_sampler, val_indices = get_train_and_val_sampler(trainset, balanced_training=True)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, num_workers=4, sampler=train_sampler)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, num_workers=4, sampler=val_sampler)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "# dataset_sizes = {\"train\": len(train_indices), \"val\": len(val_indices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_counts = np.zeros(trainset.n_classes)\n",
    "\n",
    "for batch in train_loader:\n",
    "    X, y = batch\n",
    "    y_counts += np.bincount(y, minlength=20)\n",
    "    \n",
    "print(y_counts)\n",
    "print(y_counts / y_counts.sum())\n",
    "print(y_counts.sum())\n",
    "\n",
    "y_counts = np.zeros(valset.n_classes)\n",
    "\n",
    "for batch in val_loader:\n",
    "    X, y = batch\n",
    "    y_counts += np.bincount(y, minlength=20)\n",
    "    \n",
    "print(y_counts)\n",
    "print(y_counts / y_counts.sum())\n",
    "print(y_counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix_tr\n",
    "plt.imshow(conf_matrix_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/few-shot-learning/\"))\n",
    "from few_shot.transfer import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'resnet50'\n",
      "=> Running 100 epochs of fine-tuning (top20)\n",
      "Epoch: [0][  0/282]\tLoss 2.9906e+00 (avg: 2.9906e+00)\tAcc@1   4.69 (avg:   4.69)\tAcc@5  26.56 (avg:  26.56)\tTime  8.209 (avg:  8.209)\tData  2.656 (avg:  2.656)\n",
      "Epoch: [0][ 10/282]\tLoss 7.6899e-01 (avg: 1.5784e+00)\tAcc@1  76.56 (avg:  54.69)\tAcc@5  95.31 (avg:  83.81)\tTime  1.863 (avg:  2.431)\tData  0.000 (avg:  0.242)\n",
      "Epoch: [0][ 20/282]\tLoss 8.5276e-01 (avg: 1.2136e+00)\tAcc@1  73.44 (avg:  64.06)\tAcc@5  98.44 (avg:  90.92)\tTime  1.855 (avg:  2.160)\tData  0.000 (avg:  0.127)\n",
      "Epoch: [0][ 30/282]\tLoss 6.4250e-01 (avg: 1.0028e+00)\tAcc@1  76.56 (avg:  70.46)\tAcc@5  98.44 (avg:  93.70)\tTime  1.875 (avg:  2.065)\tData  0.000 (avg:  0.087)\n",
      "Epoch: [0][ 40/282]\tLoss 3.6353e-01 (avg: 8.7969e-01)\tAcc@1  90.62 (avg:  73.93)\tAcc@5  98.44 (avg:  95.08)\tTime  1.865 (avg:  2.019)\tData  0.000 (avg:  0.066)\n",
      "Epoch: [0][ 50/282]\tLoss 4.9074e-01 (avg: 8.0449e-01)\tAcc@1  87.50 (avg:  76.07)\tAcc@5  98.44 (avg:  95.93)\tTime  1.857 (avg:  1.990)\tData  0.000 (avg:  0.053)\n",
      "Epoch: [0][ 60/282]\tLoss 4.7982e-01 (avg: 7.4998e-01)\tAcc@1  84.38 (avg:  77.41)\tAcc@5  98.44 (avg:  96.52)\tTime  1.874 (avg:  1.970)\tData  0.000 (avg:  0.045)\n",
      "Epoch: [0][ 70/282]\tLoss 2.7676e-01 (avg: 6.9720e-01)\tAcc@1  92.19 (avg:  78.94)\tAcc@5 100.00 (avg:  97.01)\tTime  1.873 (avg:  1.956)\tData  0.000 (avg:  0.039)\n",
      "Epoch: [0][ 80/282]\tLoss 5.2083e-01 (avg: 6.6399e-01)\tAcc@1  84.38 (avg:  79.80)\tAcc@5 100.00 (avg:  97.32)\tTime  1.867 (avg:  1.945)\tData  0.000 (avg:  0.034)\n",
      "Epoch: [0][ 90/282]\tLoss 4.2652e-01 (avg: 6.3347e-01)\tAcc@1  82.81 (avg:  80.67)\tAcc@5 100.00 (avg:  97.60)\tTime  1.875 (avg:  1.937)\tData  0.000 (avg:  0.031)\n",
      "Epoch: [0][100/282]\tLoss 5.0004e-01 (avg: 6.0551e-01)\tAcc@1  76.56 (avg:  81.40)\tAcc@5 100.00 (avg:  97.83)\tTime  1.874 (avg:  1.930)\tData  0.000 (avg:  0.028)\n",
      "Epoch: [0][110/282]\tLoss 3.6740e-01 (avg: 5.7911e-01)\tAcc@1  92.19 (avg:  82.33)\tAcc@5  98.44 (avg:  97.99)\tTime  1.856 (avg:  1.925)\tData  0.000 (avg:  0.025)\n",
      "Epoch: [0][120/282]\tLoss 1.5278e-01 (avg: 5.5537e-01)\tAcc@1  98.44 (avg:  83.10)\tAcc@5 100.00 (avg:  98.11)\tTime  1.876 (avg:  1.920)\tData  0.000 (avg:  0.023)\n",
      "Epoch: [0][130/282]\tLoss 3.4589e-01 (avg: 5.3840e-01)\tAcc@1  92.19 (avg:  83.61)\tAcc@5  98.44 (avg:  98.22)\tTime  1.858 (avg:  1.916)\tData  0.000 (avg:  0.022)\n",
      "Epoch: [0][140/282]\tLoss 3.3320e-01 (avg: 5.2217e-01)\tAcc@1  89.06 (avg:  84.10)\tAcc@5  98.44 (avg:  98.32)\tTime  1.870 (avg:  1.913)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [0][150/282]\tLoss 2.4827e-01 (avg: 5.0691e-01)\tAcc@1  92.19 (avg:  84.56)\tAcc@5 100.00 (avg:  98.41)\tTime  1.872 (avg:  1.910)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [0][160/282]\tLoss 2.4605e-01 (avg: 4.9259e-01)\tAcc@1  90.62 (avg:  84.88)\tAcc@5 100.00 (avg:  98.51)\tTime  1.869 (avg:  1.908)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [0][170/282]\tLoss 1.5452e-01 (avg: 4.7994e-01)\tAcc@1  95.31 (avg:  85.28)\tAcc@5 100.00 (avg:  98.56)\tTime  1.881 (avg:  1.906)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [0][180/282]\tLoss 1.7957e-01 (avg: 4.6927e-01)\tAcc@1  92.19 (avg:  85.62)\tAcc@5 100.00 (avg:  98.62)\tTime  1.883 (avg:  1.904)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [0][190/282]\tLoss 3.2709e-01 (avg: 4.5817e-01)\tAcc@1  92.19 (avg:  85.98)\tAcc@5 100.00 (avg:  98.67)\tTime  1.861 (avg:  1.902)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [0][200/282]\tLoss 1.9554e-01 (avg: 4.4904e-01)\tAcc@1  93.75 (avg:  86.26)\tAcc@5 100.00 (avg:  98.73)\tTime  1.873 (avg:  1.900)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [0][210/282]\tLoss 2.0904e-01 (avg: 4.4243e-01)\tAcc@1  95.31 (avg:  86.50)\tAcc@5 100.00 (avg:  98.78)\tTime  1.866 (avg:  1.899)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [0][220/282]\tLoss 2.8770e-01 (avg: 4.3633e-01)\tAcc@1  93.75 (avg:  86.64)\tAcc@5 100.00 (avg:  98.83)\tTime  1.875 (avg:  1.898)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [0][230/282]\tLoss 3.1532e-01 (avg: 4.3012e-01)\tAcc@1  89.06 (avg:  86.77)\tAcc@5 100.00 (avg:  98.87)\tTime  1.864 (avg:  1.896)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [0][240/282]\tLoss 1.6795e-01 (avg: 4.2508e-01)\tAcc@1  95.31 (avg:  86.93)\tAcc@5 100.00 (avg:  98.90)\tTime  1.875 (avg:  1.895)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [0][250/282]\tLoss 3.0072e-01 (avg: 4.1971e-01)\tAcc@1  90.62 (avg:  87.08)\tAcc@5 100.00 (avg:  98.94)\tTime  1.873 (avg:  1.894)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [0][260/282]\tLoss 1.8476e-01 (avg: 4.1380e-01)\tAcc@1  96.88 (avg:  87.29)\tAcc@5 100.00 (avg:  98.96)\tTime  1.868 (avg:  1.893)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [0][270/282]\tLoss 2.2357e-01 (avg: 4.0836e-01)\tAcc@1  92.19 (avg:  87.44)\tAcc@5 100.00 (avg:  99.00)\tTime  1.893 (avg:  1.893)\tData  0.000 (avg:  0.011)\n",
      "Epoch: [0][280/282]\tLoss 2.8744e-01 (avg: 4.0329e-01)\tAcc@1  89.06 (avg:  87.59)\tAcc@5 100.00 (avg:  99.03)\tTime  1.872 (avg:  1.892)\tData  0.000 (avg:  0.011)\n",
      "Test: [ 0/29]\tLoss 7.6961e-01 (avg: 7.6961e-01)\tAcc@1  68.75 (avg:  68.75)\tAcc@5  98.44 (avg:  98.44)\n",
      "Test: [10/29]\tLoss 9.0116e-01 (avg: 1.1006e+00)\tAcc@1  62.50 (avg:  62.50)\tAcc@5  98.44 (avg:  98.15)\n",
      "Test: [20/29]\tLoss 1.1106e+00 (avg: 1.1474e+00)\tAcc@1  57.81 (avg:  60.12)\tAcc@5  96.88 (avg:  98.29)\n",
      " * Acc@1 59.889 Acc@5 98.389\n",
      "Epoch: [1][  0/282]\tLoss 2.1577e-01 (avg: 2.1577e-01)\tAcc@1  89.06 (avg:  89.06)\tAcc@5 100.00 (avg: 100.00)\tTime  4.928 (avg:  4.928)\tData  3.073 (avg:  3.073)\n",
      "Epoch: [1][ 10/282]\tLoss 2.6480e-01 (avg: 2.6495e-01)\tAcc@1  87.50 (avg:  90.20)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  2.144)\tData  0.000 (avg:  0.281)\n",
      "Epoch: [1][ 20/282]\tLoss 1.5325e-01 (avg: 2.5223e-01)\tAcc@1  93.75 (avg:  91.22)\tAcc@5 100.00 (avg:  99.85)\tTime  1.871 (avg:  2.013)\tData  0.000 (avg:  0.148)\n",
      "Epoch: [1][ 30/282]\tLoss 2.5397e-01 (avg: 2.4357e-01)\tAcc@1  90.62 (avg:  91.68)\tAcc@5 100.00 (avg:  99.85)\tTime  1.871 (avg:  1.967)\tData  0.000 (avg:  0.101)\n",
      "Epoch: [1][ 40/282]\tLoss 3.1700e-01 (avg: 2.4501e-01)\tAcc@1  87.50 (avg:  91.58)\tAcc@5 100.00 (avg:  99.77)\tTime  1.879 (avg:  1.944)\tData  0.000 (avg:  0.076)\n",
      "Epoch: [1][ 50/282]\tLoss 1.9039e-01 (avg: 2.3714e-01)\tAcc@1  95.31 (avg:  91.97)\tAcc@5 100.00 (avg:  99.82)\tTime  1.866 (avg:  1.930)\tData  0.000 (avg:  0.062)\n",
      "Epoch: [1][ 60/282]\tLoss 1.6927e-01 (avg: 2.3442e-01)\tAcc@1  95.31 (avg:  92.14)\tAcc@5 100.00 (avg:  99.82)\tTime  1.869 (avg:  1.920)\tData  0.000 (avg:  0.052)\n",
      "Epoch: [1][ 70/282]\tLoss 3.1649e-01 (avg: 2.3637e-01)\tAcc@1  90.62 (avg:  92.19)\tAcc@5 100.00 (avg:  99.82)\tTime  1.873 (avg:  1.913)\tData  0.000 (avg:  0.045)\n",
      "Epoch: [1][ 80/282]\tLoss 1.8377e-01 (avg: 2.3579e-01)\tAcc@1  90.62 (avg:  92.25)\tAcc@5 100.00 (avg:  99.83)\tTime  1.870 (avg:  1.908)\tData  0.000 (avg:  0.039)\n",
      "Epoch: [1][ 90/282]\tLoss 1.1049e-01 (avg: 2.3010e-01)\tAcc@1  96.88 (avg:  92.48)\tAcc@5 100.00 (avg:  99.85)\tTime  1.874 (avg:  1.904)\tData  0.000 (avg:  0.035)\n",
      "Epoch: [1][100/282]\tLoss 1.8014e-01 (avg: 2.3272e-01)\tAcc@1  95.31 (avg:  92.47)\tAcc@5 100.00 (avg:  99.83)\tTime  1.860 (avg:  1.900)\tData  0.000 (avg:  0.032)\n",
      "Epoch: [1][110/282]\tLoss 3.3867e-01 (avg: 2.3123e-01)\tAcc@1  87.50 (avg:  92.48)\tAcc@5 100.00 (avg:  99.83)\tTime  1.883 (avg:  1.898)\tData  0.000 (avg:  0.029)\n",
      "Epoch: [1][120/282]\tLoss 3.1749e-01 (avg: 2.2888e-01)\tAcc@1  90.62 (avg:  92.59)\tAcc@5 100.00 (avg:  99.85)\tTime  1.869 (avg:  1.895)\tData  0.000 (avg:  0.027)\n",
      "Epoch: [1][130/282]\tLoss 2.9587e-01 (avg: 2.2939e-01)\tAcc@1  85.94 (avg:  92.56)\tAcc@5 100.00 (avg:  99.83)\tTime  1.880 (avg:  1.893)\tData  0.000 (avg:  0.025)\n",
      "Epoch: [1][140/282]\tLoss 2.4297e-01 (avg: 2.2884e-01)\tAcc@1  92.19 (avg:  92.63)\tAcc@5 100.00 (avg:  99.84)\tTime  1.865 (avg:  1.892)\tData  0.000 (avg:  0.023)\n",
      "Epoch: [1][150/282]\tLoss 1.0319e-01 (avg: 2.2567e-01)\tAcc@1  98.44 (avg:  92.73)\tAcc@5 100.00 (avg:  99.86)\tTime  1.876 (avg:  1.890)\tData  0.000 (avg:  0.022)\n",
      "Epoch: [1][160/282]\tLoss 2.2745e-01 (avg: 2.2378e-01)\tAcc@1  90.62 (avg:  92.81)\tAcc@5 100.00 (avg:  99.86)\tTime  1.873 (avg:  1.889)\tData  0.000 (avg:  0.021)\n",
      "Epoch: [1][170/282]\tLoss 3.8025e-01 (avg: 2.2094e-01)\tAcc@1  85.94 (avg:  92.85)\tAcc@5 100.00 (avg:  99.87)\tTime  1.859 (avg:  1.888)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [1][180/282]\tLoss 1.2488e-01 (avg: 2.2173e-01)\tAcc@1  98.44 (avg:  92.86)\tAcc@5 100.00 (avg:  99.88)\tTime  1.867 (avg:  1.887)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [1][190/282]\tLoss 1.8884e-01 (avg: 2.1947e-01)\tAcc@1  95.31 (avg:  92.93)\tAcc@5 100.00 (avg:  99.88)\tTime  1.870 (avg:  1.886)\tData  0.000 (avg:  0.018)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][200/282]\tLoss 1.1775e-01 (avg: 2.1660e-01)\tAcc@1  98.44 (avg:  93.02)\tAcc@5 100.00 (avg:  99.88)\tTime  1.876 (avg:  1.885)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [1][210/282]\tLoss 2.1442e-01 (avg: 2.1496e-01)\tAcc@1  92.19 (avg:  93.10)\tAcc@5 100.00 (avg:  99.87)\tTime  1.871 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [1][220/282]\tLoss 2.0315e-01 (avg: 2.1686e-01)\tAcc@1  93.75 (avg:  93.04)\tAcc@5 100.00 (avg:  99.87)\tTime  1.864 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [1][230/282]\tLoss 1.6213e-01 (avg: 2.1520e-01)\tAcc@1  96.88 (avg:  93.13)\tAcc@5 100.00 (avg:  99.88)\tTime  1.861 (avg:  1.883)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [1][240/282]\tLoss 1.9137e-01 (avg: 2.1342e-01)\tAcc@1  92.19 (avg:  93.19)\tAcc@5 100.00 (avg:  99.88)\tTime  1.867 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [1][250/282]\tLoss 1.8515e-01 (avg: 2.1298e-01)\tAcc@1  92.19 (avg:  93.17)\tAcc@5 100.00 (avg:  99.88)\tTime  1.859 (avg:  1.882)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [1][260/282]\tLoss 2.4850e-01 (avg: 2.1181e-01)\tAcc@1  93.75 (avg:  93.26)\tAcc@5 100.00 (avg:  99.87)\tTime  1.875 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [1][270/282]\tLoss 1.1400e-01 (avg: 2.1041e-01)\tAcc@1  96.88 (avg:  93.30)\tAcc@5 100.00 (avg:  99.88)\tTime  1.863 (avg:  1.881)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [1][280/282]\tLoss 1.9369e-01 (avg: 2.0923e-01)\tAcc@1  93.75 (avg:  93.34)\tAcc@5 100.00 (avg:  99.88)\tTime  1.867 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Test: [ 0/29]\tLoss 2.1012e-01 (avg: 2.1012e-01)\tAcc@1  89.06 (avg:  89.06)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 2.8135e-01 (avg: 2.1526e-01)\tAcc@1  89.06 (avg:  91.62)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [20/29]\tLoss 1.4437e-01 (avg: 2.2525e-01)\tAcc@1  92.19 (avg:  91.74)\tAcc@5 100.00 (avg: 100.00)\n",
      " * Acc@1 92.056 Acc@5 99.944\n",
      "Epoch: [2][  0/282]\tLoss 2.1325e-01 (avg: 2.1325e-01)\tAcc@1  90.62 (avg:  90.62)\tAcc@5 100.00 (avg: 100.00)\tTime  4.801 (avg:  4.801)\tData  2.935 (avg:  2.935)\n",
      "Epoch: [2][ 10/282]\tLoss 1.3695e-01 (avg: 1.9575e-01)\tAcc@1  96.88 (avg:  93.47)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  2.131)\tData  0.000 (avg:  0.268)\n",
      "Epoch: [2][ 20/282]\tLoss 1.4775e-01 (avg: 1.7529e-01)\tAcc@1  95.31 (avg:  94.42)\tAcc@5 100.00 (avg: 100.00)\tTime  1.876 (avg:  2.005)\tData  0.000 (avg:  0.141)\n",
      "Epoch: [2][ 30/282]\tLoss 1.7299e-01 (avg: 1.6284e-01)\tAcc@1  93.75 (avg:  94.76)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  1.961)\tData  0.000 (avg:  0.096)\n",
      "Epoch: [2][ 40/282]\tLoss 1.8882e-01 (avg: 1.6767e-01)\tAcc@1  93.75 (avg:  94.44)\tAcc@5 100.00 (avg:  99.96)\tTime  1.867 (avg:  1.939)\tData  0.000 (avg:  0.073)\n",
      "Epoch: [2][ 50/282]\tLoss 1.0704e-01 (avg: 1.6801e-01)\tAcc@1  96.88 (avg:  94.49)\tAcc@5 100.00 (avg:  99.94)\tTime  1.875 (avg:  1.925)\tData  0.000 (avg:  0.059)\n",
      "Epoch: [2][ 60/282]\tLoss 3.6728e-01 (avg: 1.7221e-01)\tAcc@1  89.06 (avg:  94.34)\tAcc@5  98.44 (avg:  99.92)\tTime  1.869 (avg:  1.916)\tData  0.000 (avg:  0.050)\n",
      "Epoch: [2][ 70/282]\tLoss 1.1214e-01 (avg: 1.7494e-01)\tAcc@1  95.31 (avg:  94.21)\tAcc@5 100.00 (avg:  99.89)\tTime  1.859 (avg:  1.910)\tData  0.000 (avg:  0.043)\n",
      "Epoch: [2][ 80/282]\tLoss 1.1070e-01 (avg: 1.7164e-01)\tAcc@1  95.31 (avg:  94.31)\tAcc@5 100.00 (avg:  99.90)\tTime  1.876 (avg:  1.905)\tData  0.000 (avg:  0.038)\n",
      "Epoch: [2][ 90/282]\tLoss 9.9925e-02 (avg: 1.7227e-01)\tAcc@1  98.44 (avg:  94.33)\tAcc@5 100.00 (avg:  99.90)\tTime  1.864 (avg:  1.901)\tData  0.000 (avg:  0.034)\n",
      "Epoch: [2][100/282]\tLoss 3.5401e-01 (avg: 1.7822e-01)\tAcc@1  89.06 (avg:  94.14)\tAcc@5 100.00 (avg:  99.88)\tTime  1.873 (avg:  1.898)\tData  0.000 (avg:  0.031)\n",
      "Epoch: [2][110/282]\tLoss 2.9958e-01 (avg: 1.8029e-01)\tAcc@1  90.62 (avg:  94.00)\tAcc@5 100.00 (avg:  99.89)\tTime  1.875 (avg:  1.896)\tData  0.000 (avg:  0.028)\n",
      "Epoch: [2][120/282]\tLoss 1.6044e-01 (avg: 1.8143e-01)\tAcc@1  93.75 (avg:  94.01)\tAcc@5 100.00 (avg:  99.88)\tTime  1.872 (avg:  1.894)\tData  0.000 (avg:  0.026)\n",
      "Epoch: [2][130/282]\tLoss 2.9066e-01 (avg: 1.8188e-01)\tAcc@1  92.19 (avg:  94.00)\tAcc@5 100.00 (avg:  99.89)\tTime  1.853 (avg:  1.892)\tData  0.000 (avg:  0.024)\n",
      "Epoch: [2][140/282]\tLoss 2.6355e-01 (avg: 1.8312e-01)\tAcc@1  93.75 (avg:  93.97)\tAcc@5 100.00 (avg:  99.89)\tTime  1.878 (avg:  1.890)\tData  0.000 (avg:  0.022)\n",
      "Epoch: [2][150/282]\tLoss 1.1783e-01 (avg: 1.8192e-01)\tAcc@1  95.31 (avg:  94.08)\tAcc@5 100.00 (avg:  99.89)\tTime  1.893 (avg:  1.889)\tData  0.000 (avg:  0.021)\n",
      "Epoch: [2][160/282]\tLoss 2.9142e-01 (avg: 1.8148e-01)\tAcc@1  92.19 (avg:  94.10)\tAcc@5  98.44 (avg:  99.87)\tTime  1.867 (avg:  1.888)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [2][170/282]\tLoss 1.4662e-01 (avg: 1.8061e-01)\tAcc@1  95.31 (avg:  94.10)\tAcc@5 100.00 (avg:  99.87)\tTime  1.868 (avg:  1.887)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [2][180/282]\tLoss 2.1861e-01 (avg: 1.8246e-01)\tAcc@1  90.62 (avg:  94.01)\tAcc@5 100.00 (avg:  99.88)\tTime  1.866 (avg:  1.886)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [2][190/282]\tLoss 1.4291e-01 (avg: 1.8078e-01)\tAcc@1  92.19 (avg:  94.07)\tAcc@5 100.00 (avg:  99.89)\tTime  1.887 (avg:  1.885)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [2][200/282]\tLoss 1.1220e-01 (avg: 1.7774e-01)\tAcc@1  96.88 (avg:  94.20)\tAcc@5 100.00 (avg:  99.89)\tTime  1.874 (avg:  1.884)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [2][210/282]\tLoss 1.0867e-01 (avg: 1.7671e-01)\tAcc@1  95.31 (avg:  94.18)\tAcc@5 100.00 (avg:  99.90)\tTime  1.863 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [2][220/282]\tLoss 1.9971e-01 (avg: 1.7786e-01)\tAcc@1  96.88 (avg:  94.13)\tAcc@5 100.00 (avg:  99.90)\tTime  1.865 (avg:  1.883)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [2][230/282]\tLoss 7.7721e-02 (avg: 1.7666e-01)\tAcc@1  98.44 (avg:  94.17)\tAcc@5 100.00 (avg:  99.89)\tTime  1.877 (avg:  1.882)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [2][240/282]\tLoss 1.4906e-01 (avg: 1.7572e-01)\tAcc@1  95.31 (avg:  94.18)\tAcc@5 100.00 (avg:  99.90)\tTime  1.863 (avg:  1.882)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [2][250/282]\tLoss 1.2778e-01 (avg: 1.7478e-01)\tAcc@1  95.31 (avg:  94.25)\tAcc@5 100.00 (avg:  99.89)\tTime  1.882 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [2][260/282]\tLoss 6.9496e-02 (avg: 1.7367e-01)\tAcc@1 100.00 (avg:  94.31)\tAcc@5 100.00 (avg:  99.89)\tTime  1.880 (avg:  1.881)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [2][270/282]\tLoss 2.8217e-01 (avg: 1.7344e-01)\tAcc@1  90.62 (avg:  94.33)\tAcc@5 100.00 (avg:  99.88)\tTime  1.873 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [2][280/282]\tLoss 7.9963e-02 (avg: 1.7349e-01)\tAcc@1  96.88 (avg:  94.33)\tAcc@5 100.00 (avg:  99.88)\tTime  1.853 (avg:  1.880)\tData  0.000 (avg:  0.012)\n",
      "Test: [ 0/29]\tLoss 5.9054e-01 (avg: 5.9054e-01)\tAcc@1  84.38 (avg:  84.38)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 2.1641e-01 (avg: 3.0515e-01)\tAcc@1  95.31 (avg:  90.48)\tAcc@5  98.44 (avg:  99.72)\n",
      "Test: [20/29]\tLoss 2.9749e-01 (avg: 3.2593e-01)\tAcc@1  90.62 (avg:  89.43)\tAcc@5 100.00 (avg:  99.63)\n",
      " * Acc@1 89.500 Acc@5 99.667\n",
      "Epoch: [3][  0/282]\tLoss 1.8987e-01 (avg: 1.8987e-01)\tAcc@1  92.19 (avg:  92.19)\tAcc@5 100.00 (avg: 100.00)\tTime  4.774 (avg:  4.774)\tData  2.890 (avg:  2.890)\n",
      "Epoch: [3][ 10/282]\tLoss 1.6753e-01 (avg: 1.6887e-01)\tAcc@1  95.31 (avg:  94.74)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  2.135)\tData  0.000 (avg:  0.264)\n",
      "Epoch: [3][ 20/282]\tLoss 1.4205e-01 (avg: 1.7143e-01)\tAcc@1  98.44 (avg:  94.87)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  2.009)\tData  0.000 (avg:  0.139)\n",
      "Epoch: [3][ 30/282]\tLoss 6.0665e-02 (avg: 1.5784e-01)\tAcc@1  96.88 (avg:  95.11)\tAcc@5 100.00 (avg: 100.00)\tTime  1.856 (avg:  1.964)\tData  0.000 (avg:  0.095)\n",
      "Epoch: [3][ 40/282]\tLoss 3.7470e-01 (avg: 1.6125e-01)\tAcc@1  89.06 (avg:  95.08)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  1.941)\tData  0.000 (avg:  0.072)\n",
      "Epoch: [3][ 50/282]\tLoss 1.6546e-01 (avg: 1.6427e-01)\tAcc@1  93.75 (avg:  94.85)\tAcc@5 100.00 (avg:  99.97)\tTime  1.869 (avg:  1.927)\tData  0.000 (avg:  0.058)\n",
      "Epoch: [3][ 60/282]\tLoss 1.1184e-01 (avg: 1.6211e-01)\tAcc@1  98.44 (avg:  94.88)\tAcc@5 100.00 (avg:  99.97)\tTime  1.871 (avg:  1.918)\tData  0.000 (avg:  0.049)\n",
      "Epoch: [3][ 70/282]\tLoss 7.1566e-02 (avg: 1.5319e-01)\tAcc@1  96.88 (avg:  95.20)\tAcc@5 100.00 (avg:  99.96)\tTime  1.862 (avg:  1.911)\tData  0.000 (avg:  0.042)\n",
      "Epoch: [3][ 80/282]\tLoss 1.2859e-01 (avg: 1.5227e-01)\tAcc@1  96.88 (avg:  95.16)\tAcc@5 100.00 (avg:  99.94)\tTime  1.874 (avg:  1.906)\tData  0.000 (avg:  0.037)\n",
      "Epoch: [3][ 90/282]\tLoss 2.2922e-01 (avg: 1.5097e-01)\tAcc@1  92.19 (avg:  95.16)\tAcc@5 100.00 (avg:  99.95)\tTime  1.872 (avg:  1.903)\tData  0.000 (avg:  0.033)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][100/282]\tLoss 1.0951e-01 (avg: 1.5057e-01)\tAcc@1  93.75 (avg:  95.10)\tAcc@5 100.00 (avg:  99.95)\tTime  1.888 (avg:  1.900)\tData  0.000 (avg:  0.030)\n",
      "Epoch: [3][110/282]\tLoss 1.5334e-01 (avg: 1.4849e-01)\tAcc@1  95.31 (avg:  95.16)\tAcc@5 100.00 (avg:  99.96)\tTime  1.887 (avg:  1.897)\tData  0.000 (avg:  0.027)\n",
      "Epoch: [3][120/282]\tLoss 5.1227e-02 (avg: 1.4699e-01)\tAcc@1 100.00 (avg:  95.20)\tAcc@5 100.00 (avg:  99.96)\tTime  1.872 (avg:  1.894)\tData  0.000 (avg:  0.025)\n",
      "Epoch: [3][130/282]\tLoss 9.6352e-02 (avg: 1.4581e-01)\tAcc@1  95.31 (avg:  95.21)\tAcc@5 100.00 (avg:  99.96)\tTime  1.868 (avg:  1.892)\tData  0.000 (avg:  0.024)\n",
      "Epoch: [3][140/282]\tLoss 1.6042e-01 (avg: 1.4760e-01)\tAcc@1  95.31 (avg:  95.15)\tAcc@5 100.00 (avg:  99.96)\tTime  1.870 (avg:  1.891)\tData  0.000 (avg:  0.022)\n",
      "Epoch: [3][150/282]\tLoss 1.9454e-01 (avg: 1.4797e-01)\tAcc@1  95.31 (avg:  95.15)\tAcc@5 100.00 (avg:  99.95)\tTime  1.872 (avg:  1.890)\tData  0.000 (avg:  0.021)\n",
      "Epoch: [3][160/282]\tLoss 9.1155e-02 (avg: 1.4664e-01)\tAcc@1  96.88 (avg:  95.20)\tAcc@5 100.00 (avg:  99.95)\tTime  1.878 (avg:  1.888)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [3][170/282]\tLoss 1.3422e-01 (avg: 1.4637e-01)\tAcc@1  98.44 (avg:  95.21)\tAcc@5 100.00 (avg:  99.95)\tTime  1.871 (avg:  1.887)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [3][180/282]\tLoss 1.2816e-01 (avg: 1.4754e-01)\tAcc@1  95.31 (avg:  95.12)\tAcc@5 100.00 (avg:  99.94)\tTime  1.871 (avg:  1.886)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [3][190/282]\tLoss 1.8497e-01 (avg: 1.4859e-01)\tAcc@1  92.19 (avg:  95.08)\tAcc@5 100.00 (avg:  99.93)\tTime  1.879 (avg:  1.886)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [3][200/282]\tLoss 1.1076e-01 (avg: 1.4761e-01)\tAcc@1  95.31 (avg:  95.13)\tAcc@5 100.00 (avg:  99.94)\tTime  1.860 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [3][210/282]\tLoss 8.3936e-02 (avg: 1.4814e-01)\tAcc@1  98.44 (avg:  95.08)\tAcc@5 100.00 (avg:  99.93)\tTime  1.873 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [3][220/282]\tLoss 2.4871e-01 (avg: 1.4684e-01)\tAcc@1  95.31 (avg:  95.07)\tAcc@5  98.44 (avg:  99.93)\tTime  1.870 (avg:  1.883)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [3][230/282]\tLoss 4.4950e-02 (avg: 1.4451e-01)\tAcc@1  98.44 (avg:  95.13)\tAcc@5 100.00 (avg:  99.93)\tTime  1.866 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [3][240/282]\tLoss 1.2539e-01 (avg: 1.4315e-01)\tAcc@1  95.31 (avg:  95.20)\tAcc@5 100.00 (avg:  99.94)\tTime  1.871 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [3][250/282]\tLoss 2.8498e-01 (avg: 1.4276e-01)\tAcc@1  90.62 (avg:  95.21)\tAcc@5 100.00 (avg:  99.94)\tTime  1.874 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [3][260/282]\tLoss 2.7663e-01 (avg: 1.4266e-01)\tAcc@1  92.19 (avg:  95.25)\tAcc@5 100.00 (avg:  99.94)\tTime  1.873 (avg:  1.881)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [3][270/282]\tLoss 7.3188e-02 (avg: 1.4234e-01)\tAcc@1  96.88 (avg:  95.28)\tAcc@5 100.00 (avg:  99.94)\tTime  1.878 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [3][280/282]\tLoss 3.4624e-02 (avg: 1.4151e-01)\tAcc@1 100.00 (avg:  95.31)\tAcc@5 100.00 (avg:  99.94)\tTime  1.864 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Test: [ 0/29]\tLoss 8.7464e-01 (avg: 8.7464e-01)\tAcc@1  73.44 (avg:  73.44)\tAcc@5  98.44 (avg:  98.44)\n",
      "Test: [10/29]\tLoss 1.2391e+00 (avg: 1.0309e+00)\tAcc@1  68.75 (avg:  70.88)\tAcc@5  90.62 (avg:  94.89)\n",
      "Test: [20/29]\tLoss 7.6656e-01 (avg: 9.7126e-01)\tAcc@1  81.25 (avg:  73.51)\tAcc@5  96.88 (avg:  95.09)\n",
      " * Acc@1 72.556 Acc@5 95.000\n",
      "Epoch: [4][  0/282]\tLoss 1.9004e-01 (avg: 1.9004e-01)\tAcc@1  92.19 (avg:  92.19)\tAcc@5 100.00 (avg: 100.00)\tTime  4.851 (avg:  4.851)\tData  3.005 (avg:  3.005)\n",
      "Epoch: [4][ 10/282]\tLoss 1.1076e-01 (avg: 1.2112e-01)\tAcc@1  98.44 (avg:  96.45)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  2.139)\tData  0.000 (avg:  0.275)\n",
      "Epoch: [4][ 20/282]\tLoss 1.3755e-01 (avg: 1.4893e-01)\tAcc@1  95.31 (avg:  94.94)\tAcc@5 100.00 (avg: 100.00)\tTime  1.865 (avg:  2.014)\tData  0.000 (avg:  0.144)\n",
      "Epoch: [4][ 30/282]\tLoss 1.4429e-01 (avg: 1.5144e-01)\tAcc@1  93.75 (avg:  94.86)\tAcc@5 100.00 (avg:  99.95)\tTime  1.877 (avg:  1.966)\tData  0.000 (avg:  0.098)\n",
      "Epoch: [4][ 40/282]\tLoss 1.6101e-01 (avg: 1.4339e-01)\tAcc@1  95.31 (avg:  95.20)\tAcc@5 100.00 (avg:  99.92)\tTime  1.861 (avg:  1.942)\tData  0.000 (avg:  0.074)\n",
      "Epoch: [4][ 50/282]\tLoss 3.5656e-02 (avg: 1.3706e-01)\tAcc@1 100.00 (avg:  95.56)\tAcc@5 100.00 (avg:  99.91)\tTime  1.877 (avg:  1.928)\tData  0.000 (avg:  0.060)\n",
      "Epoch: [4][ 60/282]\tLoss 1.7407e-01 (avg: 1.3315e-01)\tAcc@1  92.19 (avg:  95.52)\tAcc@5 100.00 (avg:  99.92)\tTime  1.857 (avg:  1.919)\tData  0.000 (avg:  0.050)\n",
      "Epoch: [4][ 70/282]\tLoss 1.2357e-01 (avg: 1.3241e-01)\tAcc@1  95.31 (avg:  95.47)\tAcc@5 100.00 (avg:  99.93)\tTime  1.868 (avg:  1.912)\tData  0.000 (avg:  0.044)\n",
      "Epoch: [4][ 80/282]\tLoss 8.3317e-02 (avg: 1.3279e-01)\tAcc@1  98.44 (avg:  95.54)\tAcc@5 100.00 (avg:  99.92)\tTime  1.870 (avg:  1.907)\tData  0.000 (avg:  0.038)\n",
      "Epoch: [4][ 90/282]\tLoss 3.6375e-02 (avg: 1.3323e-01)\tAcc@1  98.44 (avg:  95.54)\tAcc@5 100.00 (avg:  99.90)\tTime  1.863 (avg:  1.903)\tData  0.000 (avg:  0.034)\n",
      "Epoch: [4][100/282]\tLoss 1.1384e-01 (avg: 1.3331e-01)\tAcc@1  93.75 (avg:  95.54)\tAcc@5 100.00 (avg:  99.91)\tTime  1.853 (avg:  1.899)\tData  0.000 (avg:  0.031)\n",
      "Epoch: [4][110/282]\tLoss 5.3742e-02 (avg: 1.3248e-01)\tAcc@1  98.44 (avg:  95.58)\tAcc@5 100.00 (avg:  99.89)\tTime  1.862 (avg:  1.897)\tData  0.000 (avg:  0.028)\n",
      "Epoch: [4][120/282]\tLoss 8.1186e-02 (avg: 1.3336e-01)\tAcc@1  98.44 (avg:  95.58)\tAcc@5 100.00 (avg:  99.88)\tTime  1.856 (avg:  1.895)\tData  0.000 (avg:  0.026)\n",
      "Epoch: [4][130/282]\tLoss 1.2695e-01 (avg: 1.3532e-01)\tAcc@1  98.44 (avg:  95.53)\tAcc@5 100.00 (avg:  99.89)\tTime  1.876 (avg:  1.893)\tData  0.000 (avg:  0.024)\n",
      "Epoch: [4][140/282]\tLoss 2.3329e-01 (avg: 1.3687e-01)\tAcc@1  90.62 (avg:  95.47)\tAcc@5 100.00 (avg:  99.89)\tTime  1.866 (avg:  1.891)\tData  0.000 (avg:  0.023)\n",
      "Epoch: [4][150/282]\tLoss 9.2608e-02 (avg: 1.3579e-01)\tAcc@1  96.88 (avg:  95.50)\tAcc@5 100.00 (avg:  99.90)\tTime  1.875 (avg:  1.890)\tData  0.000 (avg:  0.021)\n",
      "Epoch: [4][160/282]\tLoss 9.0426e-02 (avg: 1.3271e-01)\tAcc@1  95.31 (avg:  95.56)\tAcc@5 100.00 (avg:  99.90)\tTime  1.874 (avg:  1.889)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [4][170/282]\tLoss 4.2148e-02 (avg: 1.3376e-01)\tAcc@1 100.00 (avg:  95.57)\tAcc@5 100.00 (avg:  99.90)\tTime  1.858 (avg:  1.888)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [4][180/282]\tLoss 6.3756e-02 (avg: 1.3292e-01)\tAcc@1  98.44 (avg:  95.59)\tAcc@5 100.00 (avg:  99.90)\tTime  1.858 (avg:  1.887)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [4][190/282]\tLoss 2.2770e-01 (avg: 1.3433e-01)\tAcc@1  90.62 (avg:  95.54)\tAcc@5  98.44 (avg:  99.89)\tTime  1.854 (avg:  1.886)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [4][200/282]\tLoss 1.1742e-01 (avg: 1.3548e-01)\tAcc@1  96.88 (avg:  95.55)\tAcc@5 100.00 (avg:  99.89)\tTime  1.879 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [4][210/282]\tLoss 1.3775e-01 (avg: 1.3553e-01)\tAcc@1  92.19 (avg:  95.56)\tAcc@5 100.00 (avg:  99.90)\tTime  1.871 (avg:  1.884)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [4][220/282]\tLoss 1.1592e-01 (avg: 1.3516e-01)\tAcc@1  95.31 (avg:  95.58)\tAcc@5 100.00 (avg:  99.89)\tTime  1.864 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [4][230/282]\tLoss 1.0192e-01 (avg: 1.3344e-01)\tAcc@1  93.75 (avg:  95.64)\tAcc@5 100.00 (avg:  99.89)\tTime  1.877 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [4][240/282]\tLoss 1.1123e-01 (avg: 1.3284e-01)\tAcc@1  95.31 (avg:  95.65)\tAcc@5 100.00 (avg:  99.90)\tTime  1.878 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [4][250/282]\tLoss 1.6169e-01 (avg: 1.3180e-01)\tAcc@1  95.31 (avg:  95.70)\tAcc@5 100.00 (avg:  99.90)\tTime  1.872 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [4][260/282]\tLoss 7.7004e-02 (avg: 1.3040e-01)\tAcc@1  98.44 (avg:  95.74)\tAcc@5 100.00 (avg:  99.90)\tTime  1.884 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [4][270/282]\tLoss 1.0518e-01 (avg: 1.2960e-01)\tAcc@1  96.88 (avg:  95.78)\tAcc@5 100.00 (avg:  99.91)\tTime  1.860 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [4][280/282]\tLoss 4.1044e-02 (avg: 1.2830e-01)\tAcc@1  98.44 (avg:  95.86)\tAcc@5 100.00 (avg:  99.91)\tTime  1.876 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Test: [ 0/29]\tLoss 2.7902e-01 (avg: 2.7902e-01)\tAcc@1  87.50 (avg:  87.50)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 2.0885e-01 (avg: 1.6430e-01)\tAcc@1  90.62 (avg:  93.47)\tAcc@5 100.00 (avg:  99.86)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [20/29]\tLoss 1.9200e-01 (avg: 1.8660e-01)\tAcc@1  92.19 (avg:  92.93)\tAcc@5 100.00 (avg:  99.93)\n",
      " * Acc@1 92.611 Acc@5 99.889\n",
      "Epoch: [5][  0/282]\tLoss 2.7068e-02 (avg: 2.7068e-02)\tAcc@1 100.00 (avg: 100.00)\tAcc@5 100.00 (avg: 100.00)\tTime  4.712 (avg:  4.712)\tData  2.851 (avg:  2.851)\n",
      "Epoch: [5][ 10/282]\tLoss 9.7999e-02 (avg: 1.2105e-01)\tAcc@1  96.88 (avg:  96.88)\tAcc@5 100.00 (avg: 100.00)\tTime  1.873 (avg:  2.122)\tData  0.000 (avg:  0.261)\n",
      "Epoch: [5][ 20/282]\tLoss 1.1010e-01 (avg: 1.1415e-01)\tAcc@1  98.44 (avg:  96.88)\tAcc@5 100.00 (avg:  99.93)\tTime  1.865 (avg:  2.002)\tData  0.000 (avg:  0.137)\n",
      "Epoch: [5][ 30/282]\tLoss 2.5010e-02 (avg: 1.1366e-01)\tAcc@1 100.00 (avg:  96.82)\tAcc@5 100.00 (avg:  99.95)\tTime  1.874 (avg:  1.959)\tData  0.000 (avg:  0.093)\n",
      "Epoch: [5][ 40/282]\tLoss 5.7810e-02 (avg: 1.0930e-01)\tAcc@1  98.44 (avg:  96.95)\tAcc@5 100.00 (avg:  99.96)\tTime  1.877 (avg:  1.938)\tData  0.000 (avg:  0.071)\n",
      "Epoch: [5][ 50/282]\tLoss 1.5856e-01 (avg: 1.0763e-01)\tAcc@1  95.31 (avg:  96.94)\tAcc@5 100.00 (avg:  99.94)\tTime  1.872 (avg:  1.925)\tData  0.000 (avg:  0.057)\n",
      "Epoch: [5][ 60/282]\tLoss 4.5407e-02 (avg: 1.0229e-01)\tAcc@1  98.44 (avg:  97.00)\tAcc@5 100.00 (avg:  99.95)\tTime  1.862 (avg:  1.916)\tData  0.000 (avg:  0.048)\n",
      "Epoch: [5][ 70/282]\tLoss 3.4247e-02 (avg: 9.6829e-02)\tAcc@1 100.00 (avg:  97.16)\tAcc@5 100.00 (avg:  99.96)\tTime  1.865 (avg:  1.910)\tData  0.000 (avg:  0.042)\n",
      "Epoch: [5][ 80/282]\tLoss 1.0755e-01 (avg: 9.3792e-02)\tAcc@1  96.88 (avg:  97.26)\tAcc@5 100.00 (avg:  99.96)\tTime  1.871 (avg:  1.904)\tData  0.000 (avg:  0.037)\n",
      "Epoch: [5][ 90/282]\tLoss 1.5393e-01 (avg: 9.1496e-02)\tAcc@1  96.88 (avg:  97.36)\tAcc@5 100.00 (avg:  99.97)\tTime  1.869 (avg:  1.901)\tData  0.000 (avg:  0.033)\n",
      "Epoch: [5][100/282]\tLoss 1.9428e-01 (avg: 9.1077e-02)\tAcc@1  95.31 (avg:  97.32)\tAcc@5 100.00 (avg:  99.97)\tTime  1.868 (avg:  1.898)\tData  0.000 (avg:  0.030)\n",
      "Epoch: [5][110/282]\tLoss 1.0766e-01 (avg: 9.0359e-02)\tAcc@1  95.31 (avg:  97.34)\tAcc@5 100.00 (avg:  99.97)\tTime  1.875 (avg:  1.895)\tData  0.000 (avg:  0.027)\n",
      "Epoch: [5][120/282]\tLoss 1.2283e-01 (avg: 8.9930e-02)\tAcc@1  96.88 (avg:  97.35)\tAcc@5 100.00 (avg:  99.97)\tTime  1.882 (avg:  1.893)\tData  0.000 (avg:  0.025)\n",
      "Epoch: [5][130/282]\tLoss 3.4265e-02 (avg: 8.7183e-02)\tAcc@1 100.00 (avg:  97.42)\tAcc@5 100.00 (avg:  99.96)\tTime  1.877 (avg:  1.892)\tData  0.000 (avg:  0.023)\n",
      "Epoch: [5][140/282]\tLoss 5.4091e-02 (avg: 8.7897e-02)\tAcc@1  96.88 (avg:  97.34)\tAcc@5 100.00 (avg:  99.97)\tTime  1.872 (avg:  1.890)\tData  0.000 (avg:  0.022)\n",
      "Epoch: [5][150/282]\tLoss 9.3978e-02 (avg: 8.8258e-02)\tAcc@1  98.44 (avg:  97.36)\tAcc@5 100.00 (avg:  99.97)\tTime  1.857 (avg:  1.889)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [5][160/282]\tLoss 6.2806e-02 (avg: 8.6228e-02)\tAcc@1  96.88 (avg:  97.41)\tAcc@5 100.00 (avg:  99.97)\tTime  1.875 (avg:  1.888)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [5][170/282]\tLoss 8.8097e-02 (avg: 8.4678e-02)\tAcc@1  98.44 (avg:  97.44)\tAcc@5 100.00 (avg:  99.97)\tTime  1.875 (avg:  1.887)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [5][180/282]\tLoss 6.2973e-02 (avg: 8.3278e-02)\tAcc@1  98.44 (avg:  97.46)\tAcc@5 100.00 (avg:  99.97)\tTime  1.873 (avg:  1.886)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [5][190/282]\tLoss 3.8904e-02 (avg: 8.2562e-02)\tAcc@1  98.44 (avg:  97.50)\tAcc@5 100.00 (avg:  99.98)\tTime  1.885 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [5][200/282]\tLoss 1.0138e-01 (avg: 8.1677e-02)\tAcc@1  96.88 (avg:  97.50)\tAcc@5 100.00 (avg:  99.98)\tTime  1.858 (avg:  1.884)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [5][210/282]\tLoss 7.7924e-02 (avg: 8.1234e-02)\tAcc@1  98.44 (avg:  97.48)\tAcc@5 100.00 (avg:  99.98)\tTime  1.892 (avg:  1.883)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [5][220/282]\tLoss 9.7339e-02 (avg: 8.0851e-02)\tAcc@1  98.44 (avg:  97.52)\tAcc@5 100.00 (avg:  99.98)\tTime  1.872 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [5][230/282]\tLoss 1.5540e-02 (avg: 7.8738e-02)\tAcc@1 100.00 (avg:  97.58)\tAcc@5 100.00 (avg:  99.98)\tTime  1.867 (avg:  1.882)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [5][240/282]\tLoss 1.1896e-01 (avg: 7.8762e-02)\tAcc@1  96.88 (avg:  97.60)\tAcc@5 100.00 (avg:  99.98)\tTime  1.861 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [5][250/282]\tLoss 8.6306e-02 (avg: 7.9049e-02)\tAcc@1  96.88 (avg:  97.57)\tAcc@5 100.00 (avg:  99.98)\tTime  1.870 (avg:  1.881)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [5][260/282]\tLoss 2.0099e-02 (avg: 7.7881e-02)\tAcc@1 100.00 (avg:  97.61)\tAcc@5 100.00 (avg:  99.98)\tTime  1.865 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [5][270/282]\tLoss 5.7248e-02 (avg: 7.7846e-02)\tAcc@1  98.44 (avg:  97.60)\tAcc@5 100.00 (avg:  99.98)\tTime  1.854 (avg:  1.880)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [5][280/282]\tLoss 8.6169e-02 (avg: 7.7786e-02)\tAcc@1  98.44 (avg:  97.60)\tAcc@5 100.00 (avg:  99.98)\tTime  1.856 (avg:  1.880)\tData  0.000 (avg:  0.012)\n",
      "Test: [ 0/29]\tLoss 1.0379e-01 (avg: 1.0379e-01)\tAcc@1  95.31 (avg:  95.31)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 1.8658e-01 (avg: 1.7720e-01)\tAcc@1  90.62 (avg:  93.32)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [20/29]\tLoss 2.2693e-01 (avg: 1.8045e-01)\tAcc@1  93.75 (avg:  93.97)\tAcc@5 100.00 (avg:  99.85)\n",
      " * Acc@1 94.111 Acc@5 99.889\n",
      "Epoch: [6][  0/282]\tLoss 8.8569e-02 (avg: 8.8569e-02)\tAcc@1  95.31 (avg:  95.31)\tAcc@5 100.00 (avg: 100.00)\tTime  4.820 (avg:  4.820)\tData  2.949 (avg:  2.949)\n",
      "Epoch: [6][ 10/282]\tLoss 6.9320e-02 (avg: 4.4273e-02)\tAcc@1  95.31 (avg:  98.44)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  2.142)\tData  0.000 (avg:  0.270)\n",
      "Epoch: [6][ 20/282]\tLoss 5.5314e-02 (avg: 6.5016e-02)\tAcc@1  98.44 (avg:  97.92)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  2.013)\tData  0.000 (avg:  0.142)\n",
      "Epoch: [6][ 30/282]\tLoss 8.0869e-02 (avg: 6.3801e-02)\tAcc@1  96.88 (avg:  98.19)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  1.967)\tData  0.000 (avg:  0.097)\n",
      "Epoch: [6][ 40/282]\tLoss 5.0884e-02 (avg: 6.1558e-02)\tAcc@1  98.44 (avg:  98.25)\tAcc@5 100.00 (avg: 100.00)\tTime  1.863 (avg:  1.943)\tData  0.000 (avg:  0.073)\n",
      "Epoch: [6][ 50/282]\tLoss 6.9749e-02 (avg: 6.0230e-02)\tAcc@1  96.88 (avg:  98.28)\tAcc@5 100.00 (avg: 100.00)\tTime  1.856 (avg:  1.929)\tData  0.000 (avg:  0.059)\n",
      "Epoch: [6][ 60/282]\tLoss 1.9349e-02 (avg: 5.5416e-02)\tAcc@1 100.00 (avg:  98.46)\tAcc@5 100.00 (avg: 100.00)\tTime  1.869 (avg:  1.919)\tData  0.000 (avg:  0.050)\n",
      "Epoch: [6][ 70/282]\tLoss 1.6773e-02 (avg: 5.4402e-02)\tAcc@1 100.00 (avg:  98.50)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  1.912)\tData  0.000 (avg:  0.043)\n",
      "Epoch: [6][ 80/282]\tLoss 3.7142e-02 (avg: 5.5723e-02)\tAcc@1  98.44 (avg:  98.42)\tAcc@5 100.00 (avg: 100.00)\tTime  1.869 (avg:  1.907)\tData  0.000 (avg:  0.038)\n",
      "Epoch: [6][ 90/282]\tLoss 5.5562e-02 (avg: 5.5518e-02)\tAcc@1  98.44 (avg:  98.40)\tAcc@5 100.00 (avg:  99.98)\tTime  1.885 (avg:  1.903)\tData  0.000 (avg:  0.034)\n",
      "Epoch: [6][100/282]\tLoss 3.0774e-02 (avg: 5.6501e-02)\tAcc@1  98.44 (avg:  98.39)\tAcc@5 100.00 (avg:  99.98)\tTime  1.876 (avg:  1.900)\tData  0.000 (avg:  0.031)\n",
      "Epoch: [6][110/282]\tLoss 5.7867e-02 (avg: 5.7447e-02)\tAcc@1  98.44 (avg:  98.34)\tAcc@5 100.00 (avg:  99.99)\tTime  1.848 (avg:  1.897)\tData  0.000 (avg:  0.028)\n",
      "Epoch: [6][120/282]\tLoss 9.7331e-02 (avg: 5.9634e-02)\tAcc@1  98.44 (avg:  98.27)\tAcc@5 100.00 (avg:  99.99)\tTime  1.863 (avg:  1.895)\tData  0.000 (avg:  0.026)\n",
      "Epoch: [6][130/282]\tLoss 1.4909e-02 (avg: 6.0569e-02)\tAcc@1 100.00 (avg:  98.21)\tAcc@5 100.00 (avg:  99.99)\tTime  1.872 (avg:  1.893)\tData  0.000 (avg:  0.024)\n",
      "Epoch: [6][140/282]\tLoss 4.4589e-02 (avg: 6.0288e-02)\tAcc@1  96.88 (avg:  98.25)\tAcc@5 100.00 (avg:  99.99)\tTime  1.873 (avg:  1.892)\tData  0.000 (avg:  0.022)\n",
      "Epoch: [6][150/282]\tLoss 3.1451e-02 (avg: 6.0010e-02)\tAcc@1 100.00 (avg:  98.24)\tAcc@5 100.00 (avg:  99.99)\tTime  1.864 (avg:  1.890)\tData  0.000 (avg:  0.021)\n",
      "Epoch: [6][160/282]\tLoss 5.6871e-02 (avg: 6.1402e-02)\tAcc@1  98.44 (avg:  98.20)\tAcc@5 100.00 (avg:  99.99)\tTime  1.851 (avg:  1.889)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [6][170/282]\tLoss 2.7158e-02 (avg: 6.1557e-02)\tAcc@1 100.00 (avg:  98.19)\tAcc@5 100.00 (avg:  99.99)\tTime  1.858 (avg:  1.888)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [6][180/282]\tLoss 1.7611e-02 (avg: 6.0695e-02)\tAcc@1 100.00 (avg:  98.20)\tAcc@5 100.00 (avg:  99.99)\tTime  1.871 (avg:  1.887)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [6][190/282]\tLoss 1.8376e-02 (avg: 5.9468e-02)\tAcc@1 100.00 (avg:  98.25)\tAcc@5 100.00 (avg:  99.99)\tTime  1.881 (avg:  1.886)\tData  0.000 (avg:  0.017)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][200/282]\tLoss 9.3172e-03 (avg: 5.9064e-02)\tAcc@1 100.00 (avg:  98.26)\tAcc@5 100.00 (avg:  99.99)\tTime  1.858 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [6][210/282]\tLoss 9.3039e-02 (avg: 5.8451e-02)\tAcc@1  95.31 (avg:  98.28)\tAcc@5 100.00 (avg:  99.99)\tTime  1.877 (avg:  1.885)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [6][220/282]\tLoss 2.6254e-02 (avg: 5.7446e-02)\tAcc@1  98.44 (avg:  98.30)\tAcc@5 100.00 (avg:  99.99)\tTime  1.873 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [6][230/282]\tLoss 4.8599e-02 (avg: 5.6898e-02)\tAcc@1  96.88 (avg:  98.32)\tAcc@5 100.00 (avg:  99.99)\tTime  1.870 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [6][240/282]\tLoss 7.6089e-02 (avg: 5.6904e-02)\tAcc@1  96.88 (avg:  98.32)\tAcc@5 100.00 (avg:  99.99)\tTime  1.872 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [6][250/282]\tLoss 4.0791e-02 (avg: 5.6552e-02)\tAcc@1  96.88 (avg:  98.33)\tAcc@5 100.00 (avg:  99.99)\tTime  1.881 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [6][260/282]\tLoss 7.4171e-02 (avg: 5.6527e-02)\tAcc@1  96.88 (avg:  98.32)\tAcc@5 100.00 (avg:  99.99)\tTime  1.872 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [6][270/282]\tLoss 4.2333e-02 (avg: 5.7052e-02)\tAcc@1  98.44 (avg:  98.27)\tAcc@5 100.00 (avg:  99.99)\tTime  1.867 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [6][280/282]\tLoss 1.0588e-01 (avg: 5.7858e-02)\tAcc@1  95.31 (avg:  98.25)\tAcc@5 100.00 (avg:  99.99)\tTime  1.870 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Test: [ 0/29]\tLoss 3.8439e-01 (avg: 3.8439e-01)\tAcc@1  89.06 (avg:  89.06)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 2.0005e-01 (avg: 1.9898e-01)\tAcc@1  95.31 (avg:  94.32)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [20/29]\tLoss 3.0057e-01 (avg: 1.9564e-01)\tAcc@1  89.06 (avg:  94.05)\tAcc@5 100.00 (avg: 100.00)\n",
      " * Acc@1 93.556 Acc@5 99.944\n",
      "Epoch: [7][  0/282]\tLoss 4.1560e-02 (avg: 4.1560e-02)\tAcc@1  98.44 (avg:  98.44)\tAcc@5 100.00 (avg: 100.00)\tTime  4.819 (avg:  4.819)\tData  2.982 (avg:  2.982)\n",
      "Epoch: [7][ 10/282]\tLoss 6.4817e-03 (avg: 5.2821e-02)\tAcc@1 100.00 (avg:  97.87)\tAcc@5 100.00 (avg: 100.00)\tTime  1.866 (avg:  2.138)\tData  0.000 (avg:  0.273)\n",
      "Epoch: [7][ 20/282]\tLoss 1.2442e-01 (avg: 6.9326e-02)\tAcc@1  93.75 (avg:  97.54)\tAcc@5 100.00 (avg: 100.00)\tTime  1.881 (avg:  2.011)\tData  0.000 (avg:  0.143)\n",
      "Epoch: [7][ 30/282]\tLoss 1.4233e-01 (avg: 6.9125e-02)\tAcc@1  96.88 (avg:  97.58)\tAcc@5 100.00 (avg: 100.00)\tTime  1.874 (avg:  1.965)\tData  0.000 (avg:  0.098)\n",
      "Epoch: [7][ 40/282]\tLoss 3.7929e-02 (avg: 7.1792e-02)\tAcc@1  98.44 (avg:  97.56)\tAcc@5 100.00 (avg:  99.96)\tTime  1.874 (avg:  1.942)\tData  0.000 (avg:  0.074)\n",
      "Epoch: [7][ 50/282]\tLoss 1.2327e-01 (avg: 7.4372e-02)\tAcc@1  95.31 (avg:  97.52)\tAcc@5 100.00 (avg:  99.97)\tTime  1.856 (avg:  1.928)\tData  0.000 (avg:  0.060)\n",
      "Epoch: [7][ 60/282]\tLoss 7.6465e-02 (avg: 7.6694e-02)\tAcc@1  95.31 (avg:  97.44)\tAcc@5 100.00 (avg:  99.92)\tTime  1.880 (avg:  1.919)\tData  0.000 (avg:  0.050)\n",
      "Epoch: [7][ 70/282]\tLoss 1.1641e-01 (avg: 7.4254e-02)\tAcc@1  95.31 (avg:  97.56)\tAcc@5 100.00 (avg:  99.93)\tTime  1.879 (avg:  1.912)\tData  0.000 (avg:  0.044)\n",
      "Epoch: [7][ 80/282]\tLoss 2.6629e-02 (avg: 7.3242e-02)\tAcc@1 100.00 (avg:  97.59)\tAcc@5 100.00 (avg:  99.92)\tTime  1.884 (avg:  1.907)\tData  0.000 (avg:  0.038)\n",
      "Epoch: [7][ 90/282]\tLoss 1.1652e-01 (avg: 7.1977e-02)\tAcc@1  95.31 (avg:  97.63)\tAcc@5 100.00 (avg:  99.93)\tTime  1.877 (avg:  1.903)\tData  0.000 (avg:  0.034)\n",
      "Epoch: [7][100/282]\tLoss 1.3626e-02 (avg: 6.9650e-02)\tAcc@1 100.00 (avg:  97.76)\tAcc@5 100.00 (avg:  99.94)\tTime  1.875 (avg:  1.900)\tData  0.000 (avg:  0.031)\n",
      "Epoch: [7][110/282]\tLoss 5.9999e-02 (avg: 6.7700e-02)\tAcc@1  96.88 (avg:  97.80)\tAcc@5 100.00 (avg:  99.94)\tTime  1.879 (avg:  1.897)\tData  0.000 (avg:  0.028)\n",
      "Epoch: [7][120/282]\tLoss 3.6823e-02 (avg: 6.6260e-02)\tAcc@1  98.44 (avg:  97.83)\tAcc@5 100.00 (avg:  99.95)\tTime  1.887 (avg:  1.895)\tData  0.000 (avg:  0.026)\n",
      "Epoch: [7][130/282]\tLoss 1.5218e-02 (avg: 6.5488e-02)\tAcc@1 100.00 (avg:  97.88)\tAcc@5 100.00 (avg:  99.95)\tTime  1.876 (avg:  1.893)\tData  0.000 (avg:  0.024)\n",
      "Epoch: [7][140/282]\tLoss 2.3151e-02 (avg: 6.5622e-02)\tAcc@1 100.00 (avg:  97.89)\tAcc@5 100.00 (avg:  99.96)\tTime  1.877 (avg:  1.891)\tData  0.000 (avg:  0.023)\n",
      "Epoch: [7][150/282]\tLoss 6.8801e-02 (avg: 6.4407e-02)\tAcc@1  96.88 (avg:  97.94)\tAcc@5 100.00 (avg:  99.96)\tTime  1.867 (avg:  1.890)\tData  0.000 (avg:  0.021)\n",
      "Epoch: [7][160/282]\tLoss 9.6477e-03 (avg: 6.2691e-02)\tAcc@1 100.00 (avg:  97.98)\tAcc@5 100.00 (avg:  99.96)\tTime  1.874 (avg:  1.889)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [7][170/282]\tLoss 2.5553e-02 (avg: 6.1496e-02)\tAcc@1 100.00 (avg:  98.04)\tAcc@5 100.00 (avg:  99.96)\tTime  1.873 (avg:  1.888)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [7][180/282]\tLoss 1.6278e-02 (avg: 6.0530e-02)\tAcc@1 100.00 (avg:  98.08)\tAcc@5 100.00 (avg:  99.97)\tTime  1.871 (avg:  1.887)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [7][190/282]\tLoss 1.4482e-02 (avg: 6.0216e-02)\tAcc@1 100.00 (avg:  98.09)\tAcc@5 100.00 (avg:  99.97)\tTime  1.874 (avg:  1.886)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [7][200/282]\tLoss 3.2901e-02 (avg: 5.9040e-02)\tAcc@1 100.00 (avg:  98.13)\tAcc@5 100.00 (avg:  99.97)\tTime  1.874 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [7][210/282]\tLoss 1.1241e-02 (avg: 5.8102e-02)\tAcc@1 100.00 (avg:  98.16)\tAcc@5 100.00 (avg:  99.97)\tTime  1.878 (avg:  1.884)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [7][220/282]\tLoss 5.0000e-02 (avg: 5.8396e-02)\tAcc@1  98.44 (avg:  98.12)\tAcc@5 100.00 (avg:  99.97)\tTime  1.861 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [7][230/282]\tLoss 6.7891e-02 (avg: 5.8108e-02)\tAcc@1  96.88 (avg:  98.11)\tAcc@5 100.00 (avg:  99.97)\tTime  1.861 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [7][240/282]\tLoss 3.2448e-02 (avg: 5.7429e-02)\tAcc@1  98.44 (avg:  98.13)\tAcc@5 100.00 (avg:  99.97)\tTime  1.861 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [7][250/282]\tLoss 2.2006e-02 (avg: 5.7984e-02)\tAcc@1 100.00 (avg:  98.11)\tAcc@5 100.00 (avg:  99.98)\tTime  1.864 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [7][260/282]\tLoss 1.5995e-02 (avg: 5.7668e-02)\tAcc@1 100.00 (avg:  98.13)\tAcc@5 100.00 (avg:  99.98)\tTime  1.855 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [7][270/282]\tLoss 1.1313e-01 (avg: 5.7649e-02)\tAcc@1  96.88 (avg:  98.13)\tAcc@5 100.00 (avg:  99.98)\tTime  1.861 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Epoch: [7][280/282]\tLoss 6.4568e-02 (avg: 5.7180e-02)\tAcc@1  98.44 (avg:  98.15)\tAcc@5 100.00 (avg:  99.98)\tTime  1.876 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Test: [ 0/29]\tLoss 1.7858e-01 (avg: 1.7858e-01)\tAcc@1  93.75 (avg:  93.75)\tAcc@5  98.44 (avg:  98.44)\n",
      "Test: [10/29]\tLoss 2.4450e-01 (avg: 2.2646e-01)\tAcc@1  93.75 (avg:  92.61)\tAcc@5 100.00 (avg:  99.72)\n",
      "Test: [20/29]\tLoss 1.9109e-01 (avg: 2.2527e-01)\tAcc@1  95.31 (avg:  93.15)\tAcc@5  98.44 (avg:  99.70)\n",
      " * Acc@1 93.611 Acc@5 99.778\n",
      "Epoch: [8][  0/282]\tLoss 1.1885e-01 (avg: 1.1885e-01)\tAcc@1  93.75 (avg:  93.75)\tAcc@5 100.00 (avg: 100.00)\tTime  4.924 (avg:  4.924)\tData  3.043 (avg:  3.043)\n",
      "Epoch: [8][ 10/282]\tLoss 6.9543e-02 (avg: 5.2364e-02)\tAcc@1  98.44 (avg:  98.30)\tAcc@5 100.00 (avg: 100.00)\tTime  1.865 (avg:  2.157)\tData  0.000 (avg:  0.278)\n",
      "Epoch: [8][ 20/282]\tLoss 1.1300e-02 (avg: 4.9459e-02)\tAcc@1 100.00 (avg:  98.66)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  2.018)\tData  0.000 (avg:  0.146)\n",
      "Epoch: [8][ 30/282]\tLoss 8.9553e-02 (avg: 4.9304e-02)\tAcc@1  96.88 (avg:  98.54)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  1.970)\tData  0.000 (avg:  0.100)\n",
      "Epoch: [8][ 40/282]\tLoss 2.9977e-02 (avg: 5.0005e-02)\tAcc@1 100.00 (avg:  98.63)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  1.946)\tData  0.000 (avg:  0.076)\n",
      "Epoch: [8][ 50/282]\tLoss 3.3637e-02 (avg: 4.7170e-02)\tAcc@1 100.00 (avg:  98.81)\tAcc@5 100.00 (avg: 100.00)\tTime  1.864 (avg:  1.931)\tData  0.000 (avg:  0.061)\n",
      "Epoch: [8][ 60/282]\tLoss 2.6513e-02 (avg: 4.8453e-02)\tAcc@1 100.00 (avg:  98.69)\tAcc@5 100.00 (avg: 100.00)\tTime  1.876 (avg:  1.921)\tData  0.000 (avg:  0.051)\n",
      "Epoch: [8][ 70/282]\tLoss 2.6691e-02 (avg: 4.9614e-02)\tAcc@1 100.00 (avg:  98.64)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  1.914)\tData  0.000 (avg:  0.044)\n",
      "Epoch: [8][ 80/282]\tLoss 2.4528e-02 (avg: 4.8780e-02)\tAcc@1 100.00 (avg:  98.67)\tAcc@5 100.00 (avg: 100.00)\tTime  1.886 (avg:  1.909)\tData  0.000 (avg:  0.039)\n",
      "Epoch: [8][ 90/282]\tLoss 3.0351e-02 (avg: 4.8721e-02)\tAcc@1  98.44 (avg:  98.61)\tAcc@5 100.00 (avg: 100.00)\tTime  1.877 (avg:  1.905)\tData  0.000 (avg:  0.035)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][100/282]\tLoss 2.2696e-02 (avg: 4.6984e-02)\tAcc@1  98.44 (avg:  98.65)\tAcc@5 100.00 (avg: 100.00)\tTime  1.874 (avg:  1.901)\tData  0.000 (avg:  0.032)\n",
      "Epoch: [8][110/282]\tLoss 3.5098e-02 (avg: 4.8905e-02)\tAcc@1  98.44 (avg:  98.52)\tAcc@5 100.00 (avg: 100.00)\tTime  1.867 (avg:  1.898)\tData  0.000 (avg:  0.029)\n",
      "Epoch: [8][120/282]\tLoss 1.7307e-02 (avg: 4.9331e-02)\tAcc@1 100.00 (avg:  98.51)\tAcc@5 100.00 (avg: 100.00)\tTime  1.876 (avg:  1.896)\tData  0.000 (avg:  0.027)\n",
      "Epoch: [8][130/282]\tLoss 8.8901e-02 (avg: 4.8602e-02)\tAcc@1  95.31 (avg:  98.52)\tAcc@5 100.00 (avg: 100.00)\tTime  1.873 (avg:  1.894)\tData  0.000 (avg:  0.025)\n",
      "Epoch: [8][140/282]\tLoss 8.8435e-02 (avg: 4.7720e-02)\tAcc@1  96.88 (avg:  98.56)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  1.892)\tData  0.000 (avg:  0.023)\n",
      "Epoch: [8][150/282]\tLoss 5.7923e-02 (avg: 4.6341e-02)\tAcc@1  98.44 (avg:  98.61)\tAcc@5 100.00 (avg: 100.00)\tTime  1.867 (avg:  1.891)\tData  0.000 (avg:  0.022)\n",
      "Epoch: [8][160/282]\tLoss 3.2745e-02 (avg: 4.7174e-02)\tAcc@1  98.44 (avg:  98.56)\tAcc@5 100.00 (avg: 100.00)\tTime  1.863 (avg:  1.890)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [8][170/282]\tLoss 1.5984e-02 (avg: 4.6926e-02)\tAcc@1 100.00 (avg:  98.58)\tAcc@5 100.00 (avg: 100.00)\tTime  1.876 (avg:  1.889)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [8][180/282]\tLoss 8.3754e-02 (avg: 4.7634e-02)\tAcc@1  96.88 (avg:  98.54)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  1.888)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [8][190/282]\tLoss 4.0078e-02 (avg: 4.7667e-02)\tAcc@1  98.44 (avg:  98.53)\tAcc@5 100.00 (avg: 100.00)\tTime  1.873 (avg:  1.887)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [8][200/282]\tLoss 2.7090e-02 (avg: 4.7529e-02)\tAcc@1  98.44 (avg:  98.51)\tAcc@5 100.00 (avg: 100.00)\tTime  1.889 (avg:  1.886)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [8][210/282]\tLoss 7.0306e-03 (avg: 4.8049e-02)\tAcc@1 100.00 (avg:  98.50)\tAcc@5 100.00 (avg: 100.00)\tTime  1.861 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [8][220/282]\tLoss 3.4389e-02 (avg: 4.7877e-02)\tAcc@1  98.44 (avg:  98.50)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [8][230/282]\tLoss 1.0708e-01 (avg: 4.7923e-02)\tAcc@1  98.44 (avg:  98.53)\tAcc@5 100.00 (avg: 100.00)\tTime  1.874 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [8][240/282]\tLoss 1.1829e-02 (avg: 4.7334e-02)\tAcc@1 100.00 (avg:  98.55)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [8][250/282]\tLoss 1.3580e-02 (avg: 4.6653e-02)\tAcc@1 100.00 (avg:  98.57)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [8][260/282]\tLoss 1.1451e-02 (avg: 4.6737e-02)\tAcc@1 100.00 (avg:  98.55)\tAcc@5 100.00 (avg: 100.00)\tTime  1.880 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [8][270/282]\tLoss 8.4315e-02 (avg: 4.6223e-02)\tAcc@1  95.31 (avg:  98.55)\tAcc@5 100.00 (avg: 100.00)\tTime  1.866 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [8][280/282]\tLoss 2.8263e-02 (avg: 4.5679e-02)\tAcc@1  98.44 (avg:  98.58)\tAcc@5 100.00 (avg: 100.00)\tTime  1.869 (avg:  1.881)\tData  0.000 (avg:  0.012)\n",
      "Test: [ 0/29]\tLoss 3.0955e-01 (avg: 3.0955e-01)\tAcc@1  90.62 (avg:  90.62)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 1.4765e-01 (avg: 1.7540e-01)\tAcc@1  95.31 (avg:  94.74)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [20/29]\tLoss 1.4489e-01 (avg: 1.9594e-01)\tAcc@1  95.31 (avg:  93.90)\tAcc@5 100.00 (avg:  99.85)\n",
      " * Acc@1 94.167 Acc@5 99.889\n",
      "Epoch: [9][  0/282]\tLoss 8.1438e-03 (avg: 8.1438e-03)\tAcc@1 100.00 (avg: 100.00)\tAcc@5 100.00 (avg: 100.00)\tTime  5.093 (avg:  5.093)\tData  3.232 (avg:  3.232)\n",
      "Epoch: [9][ 10/282]\tLoss 3.5203e-02 (avg: 5.1520e-02)\tAcc@1 100.00 (avg:  98.58)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  2.155)\tData  0.000 (avg:  0.295)\n",
      "Epoch: [9][ 20/282]\tLoss 7.9185e-02 (avg: 6.5427e-02)\tAcc@1  96.88 (avg:  98.36)\tAcc@5 100.00 (avg:  99.93)\tTime  1.874 (avg:  2.021)\tData  0.000 (avg:  0.155)\n",
      "Epoch: [9][ 30/282]\tLoss 1.1600e-01 (avg: 7.1911e-02)\tAcc@1  96.88 (avg:  98.08)\tAcc@5 100.00 (avg:  99.95)\tTime  1.865 (avg:  1.972)\tData  0.000 (avg:  0.106)\n",
      "Epoch: [9][ 40/282]\tLoss 1.9873e-01 (avg: 7.2594e-02)\tAcc@1  95.31 (avg:  97.90)\tAcc@5 100.00 (avg:  99.96)\tTime  1.864 (avg:  1.947)\tData  0.000 (avg:  0.080)\n",
      "Epoch: [9][ 50/282]\tLoss 1.6379e-02 (avg: 6.8933e-02)\tAcc@1 100.00 (avg:  97.98)\tAcc@5 100.00 (avg:  99.97)\tTime  1.873 (avg:  1.932)\tData  0.000 (avg:  0.065)\n",
      "Epoch: [9][ 60/282]\tLoss 9.3331e-02 (avg: 6.5245e-02)\tAcc@1  98.44 (avg:  98.10)\tAcc@5 100.00 (avg:  99.97)\tTime  1.875 (avg:  1.922)\tData  0.000 (avg:  0.054)\n",
      "Epoch: [9][ 70/282]\tLoss 1.2582e-02 (avg: 6.0164e-02)\tAcc@1 100.00 (avg:  98.24)\tAcc@5 100.00 (avg:  99.98)\tTime  1.878 (avg:  1.915)\tData  0.000 (avg:  0.047)\n",
      "Epoch: [9][ 80/282]\tLoss 1.2524e-02 (avg: 5.6384e-02)\tAcc@1 100.00 (avg:  98.32)\tAcc@5 100.00 (avg:  99.98)\tTime  1.868 (avg:  1.909)\tData  0.000 (avg:  0.041)\n",
      "Epoch: [9][ 90/282]\tLoss 8.9365e-02 (avg: 5.3596e-02)\tAcc@1  98.44 (avg:  98.42)\tAcc@5 100.00 (avg:  99.98)\tTime  1.862 (avg:  1.905)\tData  0.000 (avg:  0.037)\n",
      "Epoch: [9][100/282]\tLoss 4.4584e-02 (avg: 5.2379e-02)\tAcc@1  98.44 (avg:  98.44)\tAcc@5 100.00 (avg:  99.98)\tTime  1.879 (avg:  1.902)\tData  0.000 (avg:  0.033)\n",
      "Epoch: [9][110/282]\tLoss 9.1103e-02 (avg: 5.1958e-02)\tAcc@1  96.88 (avg:  98.42)\tAcc@5 100.00 (avg:  99.99)\tTime  1.860 (avg:  1.898)\tData  0.000 (avg:  0.031)\n",
      "Epoch: [9][120/282]\tLoss 1.5486e-02 (avg: 5.2207e-02)\tAcc@1 100.00 (avg:  98.37)\tAcc@5 100.00 (avg:  99.99)\tTime  1.869 (avg:  1.896)\tData  0.000 (avg:  0.028)\n",
      "Epoch: [9][130/282]\tLoss 3.2305e-02 (avg: 5.1539e-02)\tAcc@1 100.00 (avg:  98.39)\tAcc@5 100.00 (avg:  99.99)\tTime  1.880 (avg:  1.894)\tData  0.000 (avg:  0.026)\n",
      "Epoch: [9][140/282]\tLoss 6.8825e-03 (avg: 5.0268e-02)\tAcc@1 100.00 (avg:  98.43)\tAcc@5 100.00 (avg:  99.99)\tTime  1.869 (avg:  1.893)\tData  0.000 (avg:  0.024)\n",
      "Epoch: [9][150/282]\tLoss 2.9194e-02 (avg: 4.9889e-02)\tAcc@1  98.44 (avg:  98.42)\tAcc@5 100.00 (avg:  99.99)\tTime  1.877 (avg:  1.891)\tData  0.000 (avg:  0.023)\n",
      "Epoch: [9][160/282]\tLoss 9.0959e-03 (avg: 4.8976e-02)\tAcc@1 100.00 (avg:  98.47)\tAcc@5 100.00 (avg:  99.99)\tTime  1.865 (avg:  1.890)\tData  0.000 (avg:  0.021)\n",
      "Epoch: [9][170/282]\tLoss 7.1574e-02 (avg: 4.8454e-02)\tAcc@1  96.88 (avg:  98.47)\tAcc@5 100.00 (avg:  99.99)\tTime  1.877 (avg:  1.889)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [9][180/282]\tLoss 1.1651e-01 (avg: 4.8283e-02)\tAcc@1  96.88 (avg:  98.46)\tAcc@5 100.00 (avg:  99.99)\tTime  1.876 (avg:  1.888)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [9][190/282]\tLoss 6.2097e-02 (avg: 4.7696e-02)\tAcc@1  96.88 (avg:  98.48)\tAcc@5 100.00 (avg:  99.99)\tTime  1.876 (avg:  1.887)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [9][200/282]\tLoss 5.9299e-02 (avg: 4.7381e-02)\tAcc@1  96.88 (avg:  98.48)\tAcc@5 100.00 (avg:  99.99)\tTime  1.880 (avg:  1.886)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [9][210/282]\tLoss 9.2720e-02 (avg: 4.7151e-02)\tAcc@1  96.88 (avg:  98.50)\tAcc@5 100.00 (avg:  99.99)\tTime  1.861 (avg:  1.885)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [9][220/282]\tLoss 9.5880e-02 (avg: 4.7214e-02)\tAcc@1  98.44 (avg:  98.48)\tAcc@5 100.00 (avg:  99.99)\tTime  1.875 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [9][230/282]\tLoss 9.8636e-02 (avg: 4.7411e-02)\tAcc@1  98.44 (avg:  98.47)\tAcc@5 100.00 (avg:  99.99)\tTime  1.862 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [9][240/282]\tLoss 1.3676e-02 (avg: 4.7182e-02)\tAcc@1 100.00 (avg:  98.48)\tAcc@5 100.00 (avg:  99.99)\tTime  1.873 (avg:  1.883)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [9][250/282]\tLoss 4.4099e-02 (avg: 4.7777e-02)\tAcc@1  98.44 (avg:  98.47)\tAcc@5 100.00 (avg:  99.99)\tTime  1.855 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [9][260/282]\tLoss 4.5817e-02 (avg: 4.8144e-02)\tAcc@1  98.44 (avg:  98.45)\tAcc@5 100.00 (avg:  99.99)\tTime  1.860 (avg:  1.882)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [9][270/282]\tLoss 1.8606e-02 (avg: 4.7649e-02)\tAcc@1  98.44 (avg:  98.47)\tAcc@5 100.00 (avg:  99.99)\tTime  1.872 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [9][280/282]\tLoss 1.5023e-02 (avg: 4.7179e-02)\tAcc@1 100.00 (avg:  98.47)\tAcc@5 100.00 (avg:  99.99)\tTime  1.865 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Test: [ 0/29]\tLoss 3.4286e-01 (avg: 3.4286e-01)\tAcc@1  92.19 (avg:  92.19)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 1.6131e-01 (avg: 2.0911e-01)\tAcc@1  95.31 (avg:  94.74)\tAcc@5 100.00 (avg: 100.00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [20/29]\tLoss 1.0872e-01 (avg: 2.2209e-01)\tAcc@1  98.44 (avg:  94.20)\tAcc@5 100.00 (avg:  99.78)\n",
      " * Acc@1 94.500 Acc@5 99.833\n",
      "Epoch: [10][  0/282]\tLoss 3.1891e-02 (avg: 3.1891e-02)\tAcc@1  98.44 (avg:  98.44)\tAcc@5 100.00 (avg: 100.00)\tTime 12.540 (avg: 12.540)\tData 10.701 (avg: 10.701)\n",
      "Epoch: [10][ 10/282]\tLoss 1.9893e-02 (avg: 5.9865e-02)\tAcc@1 100.00 (avg:  98.30)\tAcc@5 100.00 (avg: 100.00)\tTime  1.865 (avg:  2.837)\tData  0.000 (avg:  0.974)\n",
      "Epoch: [10][ 20/282]\tLoss 3.7427e-02 (avg: 5.3981e-02)\tAcc@1  98.44 (avg:  98.36)\tAcc@5 100.00 (avg: 100.00)\tTime  1.869 (avg:  2.377)\tData  0.000 (avg:  0.511)\n",
      "Epoch: [10][ 30/282]\tLoss 2.5999e-02 (avg: 4.9844e-02)\tAcc@1  98.44 (avg:  98.44)\tAcc@5 100.00 (avg: 100.00)\tTime  1.876 (avg:  2.214)\tData  0.000 (avg:  0.347)\n",
      "Epoch: [10][ 40/282]\tLoss 8.7287e-03 (avg: 4.4974e-02)\tAcc@1 100.00 (avg:  98.59)\tAcc@5 100.00 (avg: 100.00)\tTime  1.877 (avg:  2.130)\tData  0.000 (avg:  0.262)\n",
      "Epoch: [10][ 50/282]\tLoss 1.6286e-02 (avg: 4.3971e-02)\tAcc@1 100.00 (avg:  98.77)\tAcc@5 100.00 (avg:  99.97)\tTime  1.877 (avg:  2.080)\tData  0.000 (avg:  0.211)\n",
      "Epoch: [10][ 60/282]\tLoss 1.6377e-02 (avg: 4.5468e-02)\tAcc@1 100.00 (avg:  98.69)\tAcc@5 100.00 (avg:  99.97)\tTime  1.863 (avg:  2.045)\tData  0.000 (avg:  0.177)\n",
      "Epoch: [10][ 70/282]\tLoss 4.4483e-02 (avg: 4.3165e-02)\tAcc@1  98.44 (avg:  98.79)\tAcc@5 100.00 (avg:  99.98)\tTime  1.865 (avg:  2.021)\tData  0.000 (avg:  0.152)\n",
      "Epoch: [10][ 80/282]\tLoss 2.7078e-02 (avg: 4.1167e-02)\tAcc@1 100.00 (avg:  98.82)\tAcc@5 100.00 (avg:  99.98)\tTime  1.857 (avg:  2.002)\tData  0.000 (avg:  0.134)\n",
      "Epoch: [10][ 90/282]\tLoss 1.4351e-02 (avg: 4.0934e-02)\tAcc@1 100.00 (avg:  98.80)\tAcc@5 100.00 (avg:  99.98)\tTime  1.860 (avg:  1.987)\tData  0.000 (avg:  0.119)\n",
      "Epoch: [10][100/282]\tLoss 5.2484e-03 (avg: 3.9243e-02)\tAcc@1 100.00 (avg:  98.82)\tAcc@5 100.00 (avg:  99.98)\tTime  1.875 (avg:  1.976)\tData  0.000 (avg:  0.107)\n",
      "Epoch: [10][110/282]\tLoss 1.3038e-02 (avg: 3.8165e-02)\tAcc@1 100.00 (avg:  98.83)\tAcc@5 100.00 (avg:  99.99)\tTime  1.865 (avg:  1.966)\tData  0.000 (avg:  0.098)\n",
      "Epoch: [10][120/282]\tLoss 1.9157e-02 (avg: 3.7072e-02)\tAcc@1 100.00 (avg:  98.88)\tAcc@5 100.00 (avg:  99.99)\tTime  1.866 (avg:  1.958)\tData  0.000 (avg:  0.090)\n",
      "Epoch: [10][130/282]\tLoss 1.5403e-02 (avg: 3.8571e-02)\tAcc@1 100.00 (avg:  98.82)\tAcc@5 100.00 (avg:  99.99)\tTime  1.862 (avg:  1.952)\tData  0.000 (avg:  0.083)\n",
      "Epoch: [10][140/282]\tLoss 4.5913e-02 (avg: 3.7358e-02)\tAcc@1  95.31 (avg:  98.85)\tAcc@5 100.00 (avg:  99.99)\tTime  1.876 (avg:  1.946)\tData  0.000 (avg:  0.077)\n",
      "Epoch: [10][150/282]\tLoss 1.3814e-02 (avg: 3.6594e-02)\tAcc@1 100.00 (avg:  98.88)\tAcc@5 100.00 (avg:  99.99)\tTime  1.850 (avg:  1.941)\tData  0.000 (avg:  0.072)\n",
      "Epoch: [10][160/282]\tLoss 2.4194e-02 (avg: 3.5813e-02)\tAcc@1  98.44 (avg:  98.91)\tAcc@5 100.00 (avg:  99.99)\tTime  1.869 (avg:  1.936)\tData  0.000 (avg:  0.068)\n",
      "Epoch: [10][170/282]\tLoss 1.2280e-02 (avg: 3.4604e-02)\tAcc@1 100.00 (avg:  98.97)\tAcc@5 100.00 (avg:  99.99)\tTime  1.872 (avg:  1.933)\tData  0.000 (avg:  0.064)\n",
      "Epoch: [10][180/282]\tLoss 8.1591e-03 (avg: 3.4742e-02)\tAcc@1 100.00 (avg:  98.96)\tAcc@5 100.00 (avg:  99.99)\tTime  1.867 (avg:  1.929)\tData  0.000 (avg:  0.061)\n",
      "Epoch: [10][190/282]\tLoss 6.5374e-03 (avg: 3.4655e-02)\tAcc@1 100.00 (avg:  98.99)\tAcc@5 100.00 (avg:  99.99)\tTime  1.863 (avg:  1.926)\tData  0.000 (avg:  0.058)\n",
      "Epoch: [10][200/282]\tLoss 1.4319e-02 (avg: 3.3844e-02)\tAcc@1 100.00 (avg:  99.03)\tAcc@5 100.00 (avg:  99.99)\tTime  1.855 (avg:  1.923)\tData  0.000 (avg:  0.055)\n",
      "Epoch: [10][210/282]\tLoss 5.2993e-02 (avg: 3.3562e-02)\tAcc@1  98.44 (avg:  99.04)\tAcc@5 100.00 (avg:  99.99)\tTime  1.890 (avg:  1.921)\tData  0.000 (avg:  0.052)\n",
      "Epoch: [10][220/282]\tLoss 4.9525e-02 (avg: 3.3569e-02)\tAcc@1  98.44 (avg:  99.04)\tAcc@5 100.00 (avg:  99.99)\tTime  1.866 (avg:  1.919)\tData  0.000 (avg:  0.050)\n",
      "Epoch: [10][230/282]\tLoss 7.6846e-03 (avg: 3.2926e-02)\tAcc@1 100.00 (avg:  99.05)\tAcc@5 100.00 (avg:  99.99)\tTime  1.861 (avg:  1.916)\tData  0.000 (avg:  0.048)\n",
      "Epoch: [10][240/282]\tLoss 3.3384e-03 (avg: 3.1945e-02)\tAcc@1 100.00 (avg:  99.09)\tAcc@5 100.00 (avg:  99.99)\tTime  1.876 (avg:  1.915)\tData  0.000 (avg:  0.046)\n",
      "Epoch: [10][250/282]\tLoss 5.3644e-02 (avg: 3.1352e-02)\tAcc@1  96.88 (avg:  99.10)\tAcc@5 100.00 (avg:  99.99)\tTime  1.873 (avg:  1.913)\tData  0.000 (avg:  0.044)\n",
      "Epoch: [10][260/282]\tLoss 1.3522e-01 (avg: 3.1546e-02)\tAcc@1  98.44 (avg:  99.11)\tAcc@5 100.00 (avg:  99.99)\tTime  1.865 (avg:  1.911)\tData  0.000 (avg:  0.042)\n",
      "Epoch: [10][270/282]\tLoss 9.3314e-03 (avg: 3.0628e-02)\tAcc@1 100.00 (avg:  99.14)\tAcc@5 100.00 (avg:  99.99)\tTime  1.861 (avg:  1.910)\tData  0.000 (avg:  0.041)\n",
      "Epoch: [10][280/282]\tLoss 3.1504e-02 (avg: 3.0731e-02)\tAcc@1  98.44 (avg:  99.13)\tAcc@5 100.00 (avg:  99.99)\tTime  1.871 (avg:  1.908)\tData  0.000 (avg:  0.040)\n",
      "Test: [ 0/29]\tLoss 3.0991e-01 (avg: 3.0991e-01)\tAcc@1  90.62 (avg:  90.62)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 1.9670e-01 (avg: 1.8390e-01)\tAcc@1  93.75 (avg:  94.18)\tAcc@5 100.00 (avg:  99.72)\n",
      "Test: [20/29]\tLoss 3.0364e-01 (avg: 1.5461e-01)\tAcc@1  92.19 (avg:  94.94)\tAcc@5 100.00 (avg:  99.85)\n",
      " * Acc@1 95.167 Acc@5 99.889\n",
      "Epoch: [11][  0/282]\tLoss 1.9371e-02 (avg: 1.9371e-02)\tAcc@1 100.00 (avg: 100.00)\tAcc@5 100.00 (avg: 100.00)\tTime  5.003 (avg:  5.003)\tData  3.156 (avg:  3.156)\n",
      "Epoch: [11][ 10/282]\tLoss 2.2665e-02 (avg: 1.6749e-02)\tAcc@1  98.44 (avg:  99.57)\tAcc@5 100.00 (avg: 100.00)\tTime  1.874 (avg:  2.147)\tData  0.000 (avg:  0.288)\n",
      "Epoch: [11][ 20/282]\tLoss 5.0347e-03 (avg: 1.3617e-02)\tAcc@1 100.00 (avg:  99.70)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  2.016)\tData  0.000 (avg:  0.152)\n",
      "Epoch: [11][ 30/282]\tLoss 6.6733e-03 (avg: 1.4322e-02)\tAcc@1 100.00 (avg:  99.70)\tAcc@5 100.00 (avg: 100.00)\tTime  1.863 (avg:  1.969)\tData  0.000 (avg:  0.103)\n",
      "Epoch: [11][ 40/282]\tLoss 3.6193e-02 (avg: 1.3575e-02)\tAcc@1  98.44 (avg:  99.70)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  1.945)\tData  0.000 (avg:  0.078)\n",
      "Epoch: [11][ 50/282]\tLoss 9.2133e-03 (avg: 1.3576e-02)\tAcc@1 100.00 (avg:  99.66)\tAcc@5 100.00 (avg: 100.00)\tTime  1.868 (avg:  1.930)\tData  0.000 (avg:  0.063)\n",
      "Epoch: [11][ 60/282]\tLoss 1.1776e-02 (avg: 1.4831e-02)\tAcc@1 100.00 (avg:  99.67)\tAcc@5 100.00 (avg: 100.00)\tTime  1.878 (avg:  1.921)\tData  0.000 (avg:  0.053)\n",
      "Epoch: [11][ 70/282]\tLoss 9.1293e-03 (avg: 1.5775e-02)\tAcc@1 100.00 (avg:  99.63)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  1.913)\tData  0.000 (avg:  0.046)\n",
      "Epoch: [11][ 80/282]\tLoss 1.7621e-03 (avg: 1.5876e-02)\tAcc@1 100.00 (avg:  99.61)\tAcc@5 100.00 (avg: 100.00)\tTime  1.886 (avg:  1.908)\tData  0.000 (avg:  0.040)\n",
      "Epoch: [11][ 90/282]\tLoss 1.7756e-03 (avg: 1.4999e-02)\tAcc@1 100.00 (avg:  99.64)\tAcc@5 100.00 (avg: 100.00)\tTime  1.853 (avg:  1.904)\tData  0.000 (avg:  0.036)\n",
      "Epoch: [11][100/282]\tLoss 6.7875e-03 (avg: 1.5433e-02)\tAcc@1 100.00 (avg:  99.63)\tAcc@5 100.00 (avg: 100.00)\tTime  1.867 (avg:  1.901)\tData  0.000 (avg:  0.033)\n",
      "Epoch: [11][110/282]\tLoss 4.2237e-02 (avg: 1.5521e-02)\tAcc@1  96.88 (avg:  99.62)\tAcc@5 100.00 (avg: 100.00)\tTime  1.873 (avg:  1.898)\tData  0.000 (avg:  0.030)\n",
      "Epoch: [11][120/282]\tLoss 3.6943e-02 (avg: 1.6353e-02)\tAcc@1  98.44 (avg:  99.60)\tAcc@5 100.00 (avg: 100.00)\tTime  1.850 (avg:  1.896)\tData  0.000 (avg:  0.028)\n",
      "Epoch: [11][130/282]\tLoss 9.8509e-03 (avg: 1.6233e-02)\tAcc@1 100.00 (avg:  99.59)\tAcc@5 100.00 (avg: 100.00)\tTime  1.868 (avg:  1.894)\tData  0.000 (avg:  0.026)\n",
      "Epoch: [11][140/282]\tLoss 3.8015e-02 (avg: 1.6280e-02)\tAcc@1  96.88 (avg:  99.58)\tAcc@5 100.00 (avg: 100.00)\tTime  1.867 (avg:  1.892)\tData  0.000 (avg:  0.024)\n",
      "Epoch: [11][150/282]\tLoss 3.0898e-03 (avg: 1.5683e-02)\tAcc@1 100.00 (avg:  99.61)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  1.891)\tData  0.000 (avg:  0.022)\n",
      "Epoch: [11][160/282]\tLoss 3.5249e-03 (avg: 1.5237e-02)\tAcc@1 100.00 (avg:  99.63)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  1.889)\tData  0.000 (avg:  0.021)\n",
      "Epoch: [11][170/282]\tLoss 3.7860e-03 (avg: 1.5628e-02)\tAcc@1 100.00 (avg:  99.62)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  1.888)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [11][180/282]\tLoss 1.5079e-03 (avg: 1.5333e-02)\tAcc@1 100.00 (avg:  99.62)\tAcc@5 100.00 (avg: 100.00)\tTime  1.883 (avg:  1.887)\tData  0.000 (avg:  0.019)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11][190/282]\tLoss 3.1639e-03 (avg: 1.5077e-02)\tAcc@1 100.00 (avg:  99.63)\tAcc@5 100.00 (avg: 100.00)\tTime  1.866 (avg:  1.886)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [11][200/282]\tLoss 2.9570e-03 (avg: 1.5026e-02)\tAcc@1 100.00 (avg:  99.63)\tAcc@5 100.00 (avg: 100.00)\tTime  1.882 (avg:  1.886)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [11][210/282]\tLoss 5.3847e-02 (avg: 1.5011e-02)\tAcc@1  98.44 (avg:  99.64)\tAcc@5 100.00 (avg: 100.00)\tTime  1.880 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [11][220/282]\tLoss 8.4640e-03 (avg: 1.4566e-02)\tAcc@1 100.00 (avg:  99.65)\tAcc@5 100.00 (avg: 100.00)\tTime  1.869 (avg:  1.884)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [11][230/282]\tLoss 4.2741e-03 (avg: 1.4327e-02)\tAcc@1 100.00 (avg:  99.67)\tAcc@5 100.00 (avg: 100.00)\tTime  1.867 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [11][240/282]\tLoss 8.8226e-03 (avg: 1.3886e-02)\tAcc@1 100.00 (avg:  99.68)\tAcc@5 100.00 (avg: 100.00)\tTime  1.858 (avg:  1.883)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [11][250/282]\tLoss 6.8424e-03 (avg: 1.3599e-02)\tAcc@1 100.00 (avg:  99.69)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [11][260/282]\tLoss 5.8697e-03 (avg: 1.3480e-02)\tAcc@1 100.00 (avg:  99.69)\tAcc@5 100.00 (avg: 100.00)\tTime  1.873 (avg:  1.882)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [11][270/282]\tLoss 4.3224e-03 (avg: 1.3216e-02)\tAcc@1 100.00 (avg:  99.69)\tAcc@5 100.00 (avg: 100.00)\tTime  1.866 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [11][280/282]\tLoss 1.2468e-02 (avg: 1.3016e-02)\tAcc@1 100.00 (avg:  99.70)\tAcc@5 100.00 (avg: 100.00)\tTime  1.857 (avg:  1.881)\tData  0.000 (avg:  0.013)\n",
      "Test: [ 0/29]\tLoss 1.2743e-01 (avg: 1.2743e-01)\tAcc@1  95.31 (avg:  95.31)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 2.2657e-01 (avg: 1.7902e-01)\tAcc@1  93.75 (avg:  94.74)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [20/29]\tLoss 5.0693e-02 (avg: 1.7173e-01)\tAcc@1  98.44 (avg:  95.16)\tAcc@5 100.00 (avg: 100.00)\n",
      " * Acc@1 95.500 Acc@5 100.000\n",
      "Epoch: [12][  0/282]\tLoss 1.3528e-03 (avg: 1.3528e-03)\tAcc@1 100.00 (avg: 100.00)\tAcc@5 100.00 (avg: 100.00)\tTime 12.465 (avg: 12.465)\tData 10.618 (avg: 10.618)\n",
      "Epoch: [12][ 10/282]\tLoss 5.7410e-03 (avg: 3.7688e-02)\tAcc@1 100.00 (avg:  98.72)\tAcc@5 100.00 (avg: 100.00)\tTime  1.868 (avg:  2.841)\tData  0.000 (avg:  0.967)\n",
      "Epoch: [12][ 20/282]\tLoss 7.3152e-02 (avg: 3.2499e-02)\tAcc@1  98.44 (avg:  98.96)\tAcc@5 100.00 (avg: 100.00)\tTime  1.894 (avg:  2.379)\tData  0.000 (avg:  0.507)\n",
      "Epoch: [12][ 30/282]\tLoss 6.0327e-03 (avg: 2.6417e-02)\tAcc@1 100.00 (avg:  99.24)\tAcc@5 100.00 (avg: 100.00)\tTime  1.853 (avg:  2.215)\tData  0.000 (avg:  0.344)\n",
      "Epoch: [12][ 40/282]\tLoss 7.7203e-03 (avg: 2.4414e-02)\tAcc@1 100.00 (avg:  99.31)\tAcc@5 100.00 (avg: 100.00)\tTime  1.855 (avg:  2.131)\tData  0.000 (avg:  0.260)\n",
      "Epoch: [12][ 50/282]\tLoss 1.2805e-02 (avg: 2.3452e-02)\tAcc@1 100.00 (avg:  99.36)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  2.080)\tData  0.000 (avg:  0.210)\n",
      "Epoch: [12][ 60/282]\tLoss 8.1689e-03 (avg: 2.0814e-02)\tAcc@1 100.00 (avg:  99.46)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  2.046)\tData  0.000 (avg:  0.176)\n",
      "Epoch: [12][ 70/282]\tLoss 1.1182e-02 (avg: 2.0682e-02)\tAcc@1 100.00 (avg:  99.43)\tAcc@5 100.00 (avg: 100.00)\tTime  1.880 (avg:  2.021)\tData  0.000 (avg:  0.151)\n",
      "Epoch: [12][ 80/282]\tLoss 2.8852e-02 (avg: 1.9500e-02)\tAcc@1  98.44 (avg:  99.46)\tAcc@5 100.00 (avg: 100.00)\tTime  1.877 (avg:  2.003)\tData  0.000 (avg:  0.133)\n",
      "Epoch: [12][ 90/282]\tLoss 1.3564e-01 (avg: 2.1971e-02)\tAcc@1  96.88 (avg:  99.38)\tAcc@5 100.00 (avg: 100.00)\tTime  1.873 (avg:  1.988)\tData  0.000 (avg:  0.118)\n",
      "Epoch: [12][100/282]\tLoss 1.4324e-02 (avg: 2.1896e-02)\tAcc@1 100.00 (avg:  99.41)\tAcc@5 100.00 (avg: 100.00)\tTime  1.880 (avg:  1.976)\tData  0.000 (avg:  0.107)\n",
      "Epoch: [12][110/282]\tLoss 8.2259e-03 (avg: 2.2406e-02)\tAcc@1 100.00 (avg:  99.41)\tAcc@5 100.00 (avg: 100.00)\tTime  1.864 (avg:  1.967)\tData  0.000 (avg:  0.097)\n",
      "Epoch: [12][120/282]\tLoss 9.5641e-02 (avg: 2.2545e-02)\tAcc@1  96.88 (avg:  99.39)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  1.959)\tData  0.000 (avg:  0.089)\n",
      "Epoch: [12][130/282]\tLoss 1.0055e-02 (avg: 2.2698e-02)\tAcc@1 100.00 (avg:  99.36)\tAcc@5 100.00 (avg: 100.00)\tTime  1.859 (avg:  1.952)\tData  0.000 (avg:  0.083)\n",
      "Epoch: [12][140/282]\tLoss 5.6531e-03 (avg: 2.1662e-02)\tAcc@1 100.00 (avg:  99.40)\tAcc@5 100.00 (avg: 100.00)\tTime  1.873 (avg:  1.946)\tData  0.000 (avg:  0.077)\n",
      "Epoch: [12][150/282]\tLoss 4.4845e-02 (avg: 2.1315e-02)\tAcc@1  98.44 (avg:  99.40)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  1.941)\tData  0.000 (avg:  0.072)\n",
      "Epoch: [12][160/282]\tLoss 4.7243e-03 (avg: 2.1399e-02)\tAcc@1 100.00 (avg:  99.40)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  1.937)\tData  0.000 (avg:  0.067)\n",
      "Epoch: [12][170/282]\tLoss 4.2914e-02 (avg: 2.1929e-02)\tAcc@1  98.44 (avg:  99.38)\tAcc@5 100.00 (avg: 100.00)\tTime  1.864 (avg:  1.933)\tData  0.000 (avg:  0.064)\n",
      "Epoch: [12][180/282]\tLoss 2.3669e-02 (avg: 2.2146e-02)\tAcc@1  98.44 (avg:  99.34)\tAcc@5 100.00 (avg: 100.00)\tTime  1.878 (avg:  1.929)\tData  0.000 (avg:  0.060)\n",
      "Epoch: [12][190/282]\tLoss 2.3167e-02 (avg: 2.2780e-02)\tAcc@1 100.00 (avg:  99.34)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  1.926)\tData  0.000 (avg:  0.057)\n",
      "Epoch: [12][200/282]\tLoss 4.3655e-03 (avg: 2.2386e-02)\tAcc@1 100.00 (avg:  99.35)\tAcc@5 100.00 (avg: 100.00)\tTime  1.874 (avg:  1.924)\tData  0.000 (avg:  0.054)\n",
      "Epoch: [12][210/282]\tLoss 8.8962e-03 (avg: 2.1979e-02)\tAcc@1 100.00 (avg:  99.36)\tAcc@5 100.00 (avg: 100.00)\tTime  1.862 (avg:  1.921)\tData  0.000 (avg:  0.052)\n",
      "Epoch: [12][220/282]\tLoss 9.1093e-03 (avg: 2.1547e-02)\tAcc@1 100.00 (avg:  99.38)\tAcc@5 100.00 (avg: 100.00)\tTime  1.874 (avg:  1.919)\tData  0.000 (avg:  0.050)\n",
      "Epoch: [12][230/282]\tLoss 4.8466e-03 (avg: 2.1011e-02)\tAcc@1 100.00 (avg:  99.39)\tAcc@5 100.00 (avg: 100.00)\tTime  1.882 (avg:  1.917)\tData  0.000 (avg:  0.047)\n",
      "Epoch: [12][240/282]\tLoss 7.6000e-02 (avg: 2.0847e-02)\tAcc@1  96.88 (avg:  99.39)\tAcc@5 100.00 (avg: 100.00)\tTime  1.881 (avg:  1.915)\tData  0.000 (avg:  0.046)\n",
      "Epoch: [12][250/282]\tLoss 9.3741e-03 (avg: 2.0513e-02)\tAcc@1 100.00 (avg:  99.40)\tAcc@5 100.00 (avg: 100.00)\tTime  1.878 (avg:  1.913)\tData  0.000 (avg:  0.044)\n",
      "Epoch: [12][260/282]\tLoss 2.9247e-03 (avg: 2.0317e-02)\tAcc@1 100.00 (avg:  99.41)\tAcc@5 100.00 (avg: 100.00)\tTime  1.878 (avg:  1.911)\tData  0.000 (avg:  0.042)\n",
      "Epoch: [12][270/282]\tLoss 3.5496e-03 (avg: 2.0081e-02)\tAcc@1 100.00 (avg:  99.42)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  1.910)\tData  0.000 (avg:  0.041)\n",
      "Epoch: [12][280/282]\tLoss 2.0371e-02 (avg: 1.9942e-02)\tAcc@1 100.00 (avg:  99.44)\tAcc@5 100.00 (avg: 100.00)\tTime  1.878 (avg:  1.908)\tData  0.000 (avg:  0.039)\n",
      "Test: [ 0/29]\tLoss 1.8956e-01 (avg: 1.8956e-01)\tAcc@1  93.75 (avg:  93.75)\tAcc@5  98.44 (avg:  98.44)\n",
      "Test: [10/29]\tLoss 1.3291e-01 (avg: 1.3771e-01)\tAcc@1  96.88 (avg:  95.74)\tAcc@5 100.00 (avg:  99.86)\n",
      "Test: [20/29]\tLoss 1.4626e-01 (avg: 1.8013e-01)\tAcc@1  95.31 (avg:  95.16)\tAcc@5 100.00 (avg:  99.93)\n",
      " * Acc@1 95.222 Acc@5 99.889\n",
      "Epoch: [13][  0/282]\tLoss 2.7911e-03 (avg: 2.7911e-03)\tAcc@1 100.00 (avg: 100.00)\tAcc@5 100.00 (avg: 100.00)\tTime  5.096 (avg:  5.096)\tData  3.235 (avg:  3.235)\n",
      "Epoch: [13][ 10/282]\tLoss 1.2888e-02 (avg: 2.5057e-02)\tAcc@1 100.00 (avg:  99.43)\tAcc@5 100.00 (avg: 100.00)\tTime  1.861 (avg:  2.164)\tData  0.000 (avg:  0.295)\n",
      "Epoch: [13][ 20/282]\tLoss 1.1291e-02 (avg: 1.9896e-02)\tAcc@1 100.00 (avg:  99.48)\tAcc@5 100.00 (avg: 100.00)\tTime  1.878 (avg:  2.024)\tData  0.000 (avg:  0.155)\n",
      "Epoch: [13][ 30/282]\tLoss 4.5072e-03 (avg: 1.4948e-02)\tAcc@1 100.00 (avg:  99.65)\tAcc@5 100.00 (avg: 100.00)\tTime  1.890 (avg:  1.975)\tData  0.000 (avg:  0.105)\n",
      "Epoch: [13][ 40/282]\tLoss 2.0726e-03 (avg: 1.3774e-02)\tAcc@1 100.00 (avg:  99.66)\tAcc@5 100.00 (avg: 100.00)\tTime  1.848 (avg:  1.949)\tData  0.000 (avg:  0.080)\n",
      "Epoch: [13][ 50/282]\tLoss 4.5343e-03 (avg: 1.3887e-02)\tAcc@1 100.00 (avg:  99.60)\tAcc@5 100.00 (avg: 100.00)\tTime  1.859 (avg:  1.933)\tData  0.000 (avg:  0.065)\n",
      "Epoch: [13][ 60/282]\tLoss 3.7391e-03 (avg: 1.6189e-02)\tAcc@1 100.00 (avg:  99.56)\tAcc@5 100.00 (avg: 100.00)\tTime  1.888 (avg:  1.923)\tData  0.000 (avg:  0.054)\n",
      "Epoch: [13][ 70/282]\tLoss 2.5546e-02 (avg: 1.5649e-02)\tAcc@1  98.44 (avg:  99.58)\tAcc@5 100.00 (avg: 100.00)\tTime  1.889 (avg:  1.916)\tData  0.000 (avg:  0.047)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][ 80/282]\tLoss 2.1968e-03 (avg: 1.4657e-02)\tAcc@1 100.00 (avg:  99.61)\tAcc@5 100.00 (avg: 100.00)\tTime  1.863 (avg:  1.910)\tData  0.000 (avg:  0.041)\n",
      "Epoch: [13][ 90/282]\tLoss 6.9413e-03 (avg: 1.4282e-02)\tAcc@1 100.00 (avg:  99.61)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  1.906)\tData  0.000 (avg:  0.037)\n",
      "Epoch: [13][100/282]\tLoss 2.8960e-03 (avg: 1.3500e-02)\tAcc@1 100.00 (avg:  99.64)\tAcc@5 100.00 (avg: 100.00)\tTime  1.871 (avg:  1.902)\tData  0.000 (avg:  0.033)\n",
      "Epoch: [13][110/282]\tLoss 4.0861e-02 (avg: 1.3043e-02)\tAcc@1  98.44 (avg:  99.66)\tAcc@5 100.00 (avg: 100.00)\tTime  1.874 (avg:  1.899)\tData  0.000 (avg:  0.031)\n",
      "Epoch: [13][120/282]\tLoss 1.0729e-02 (avg: 1.3548e-02)\tAcc@1 100.00 (avg:  99.66)\tAcc@5 100.00 (avg: 100.00)\tTime  1.866 (avg:  1.897)\tData  0.000 (avg:  0.028)\n",
      "Epoch: [13][130/282]\tLoss 3.8884e-03 (avg: 1.4379e-02)\tAcc@1 100.00 (avg:  99.65)\tAcc@5 100.00 (avg: 100.00)\tTime  1.861 (avg:  1.895)\tData  0.000 (avg:  0.026)\n",
      "Epoch: [13][140/282]\tLoss 2.1020e-02 (avg: 1.4010e-02)\tAcc@1 100.00 (avg:  99.68)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  1.893)\tData  0.000 (avg:  0.024)\n",
      "Epoch: [13][150/282]\tLoss 6.5209e-03 (avg: 1.3828e-02)\tAcc@1 100.00 (avg:  99.67)\tAcc@5 100.00 (avg: 100.00)\tTime  1.862 (avg:  1.892)\tData  0.000 (avg:  0.023)\n",
      "Epoch: [13][160/282]\tLoss 7.3746e-02 (avg: 1.4010e-02)\tAcc@1  98.44 (avg:  99.66)\tAcc@5 100.00 (avg: 100.00)\tTime  1.862 (avg:  1.890)\tData  0.000 (avg:  0.021)\n",
      "Epoch: [13][170/282]\tLoss 1.8188e-02 (avg: 1.4923e-02)\tAcc@1 100.00 (avg:  99.63)\tAcc@5 100.00 (avg: 100.00)\tTime  1.877 (avg:  1.889)\tData  0.000 (avg:  0.020)\n",
      "Epoch: [13][180/282]\tLoss 7.6844e-02 (avg: 1.5429e-02)\tAcc@1  98.44 (avg:  99.61)\tAcc@5 100.00 (avg: 100.00)\tTime  1.875 (avg:  1.888)\tData  0.000 (avg:  0.019)\n",
      "Epoch: [13][190/282]\tLoss 1.8116e-02 (avg: 1.5288e-02)\tAcc@1 100.00 (avg:  99.61)\tAcc@5 100.00 (avg: 100.00)\tTime  1.866 (avg:  1.887)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [13][200/282]\tLoss 1.6575e-02 (avg: 1.5584e-02)\tAcc@1 100.00 (avg:  99.59)\tAcc@5 100.00 (avg: 100.00)\tTime  1.874 (avg:  1.886)\tData  0.000 (avg:  0.018)\n",
      "Epoch: [13][210/282]\tLoss 2.7476e-03 (avg: 1.5387e-02)\tAcc@1 100.00 (avg:  99.59)\tAcc@5 100.00 (avg: 100.00)\tTime  1.862 (avg:  1.886)\tData  0.000 (avg:  0.017)\n",
      "Epoch: [13][220/282]\tLoss 3.3967e-03 (avg: 1.5189e-02)\tAcc@1 100.00 (avg:  99.60)\tAcc@5 100.00 (avg: 100.00)\tTime  1.872 (avg:  1.885)\tData  0.000 (avg:  0.016)\n",
      "Epoch: [13][230/282]\tLoss 1.4801e-02 (avg: 1.5258e-02)\tAcc@1 100.00 (avg:  99.60)\tAcc@5 100.00 (avg: 100.00)\tTime  1.868 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [13][240/282]\tLoss 3.8092e-02 (avg: 1.5741e-02)\tAcc@1  98.44 (avg:  99.59)\tAcc@5 100.00 (avg: 100.00)\tTime  1.861 (avg:  1.884)\tData  0.000 (avg:  0.015)\n",
      "Epoch: [13][250/282]\tLoss 4.0951e-03 (avg: 1.5397e-02)\tAcc@1 100.00 (avg:  99.61)\tAcc@5 100.00 (avg: 100.00)\tTime  1.863 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [13][260/282]\tLoss 4.9346e-03 (avg: 1.5598e-02)\tAcc@1 100.00 (avg:  99.61)\tAcc@5 100.00 (avg:  99.99)\tTime  1.867 (avg:  1.883)\tData  0.000 (avg:  0.014)\n",
      "Epoch: [13][270/282]\tLoss 3.1630e-03 (avg: 1.5650e-02)\tAcc@1 100.00 (avg:  99.61)\tAcc@5 100.00 (avg:  99.99)\tTime  1.873 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Epoch: [13][280/282]\tLoss 6.0080e-03 (avg: 1.5417e-02)\tAcc@1 100.00 (avg:  99.62)\tAcc@5 100.00 (avg:  99.99)\tTime  1.874 (avg:  1.882)\tData  0.000 (avg:  0.013)\n",
      "Test: [ 0/29]\tLoss 6.3654e-02 (avg: 6.3654e-02)\tAcc@1  96.88 (avg:  96.88)\tAcc@5 100.00 (avg: 100.00)\n",
      "Test: [10/29]\tLoss 1.5142e-01 (avg: 1.4668e-01)\tAcc@1  95.31 (avg:  94.89)\tAcc@5 100.00 (avg:  99.86)\n",
      "Test: [20/29]\tLoss 3.4094e-01 (avg: 1.6533e-01)\tAcc@1  93.75 (avg:  94.64)\tAcc@5 100.00 (avg:  99.85)\n",
      " * Acc@1 94.556 Acc@5 99.889\n",
      "Epoch: [14][  0/282]\tLoss 5.9365e-03 (avg: 5.9365e-03)\tAcc@1 100.00 (avg: 100.00)\tAcc@5 100.00 (avg: 100.00)\tTime  5.742 (avg:  5.742)\tData  3.871 (avg:  3.871)\n",
      "Epoch: [14][ 10/282]\tLoss 1.9716e-03 (avg: 1.2497e-02)\tAcc@1 100.00 (avg:  99.57)\tAcc@5 100.00 (avg: 100.00)\tTime  1.870 (avg:  2.214)\tData  0.000 (avg:  0.353)\n",
      "Epoch: [14][ 20/282]\tLoss 4.2567e-03 (avg: 1.6162e-02)\tAcc@1 100.00 (avg:  99.48)\tAcc@5 100.00 (avg: 100.00)\tTime  1.869 (avg:  2.051)\tData  0.000 (avg:  0.186)\n",
      "Epoch: [14][ 30/282]\tLoss 4.7826e-03 (avg: 1.6387e-02)\tAcc@1 100.00 (avg:  99.60)\tAcc@5 100.00 (avg:  99.95)\tTime  1.865 (avg:  1.993)\tData  0.000 (avg:  0.126)\n",
      "Epoch: [14][ 40/282]\tLoss 1.7101e-02 (avg: 1.6169e-02)\tAcc@1  98.44 (avg:  99.62)\tAcc@5 100.00 (avg:  99.96)\tTime  1.872 (avg:  1.963)\tData  0.000 (avg:  0.096)\n",
      "Epoch: [14][ 50/282]\tLoss 3.2026e-03 (avg: 1.5552e-02)\tAcc@1 100.00 (avg:  99.57)\tAcc@5 100.00 (avg:  99.97)\tTime  1.861 (avg:  1.945)\tData  0.000 (avg:  0.077)\n",
      "Epoch: [14][ 60/282]\tLoss 4.9629e-03 (avg: 1.5379e-02)\tAcc@1 100.00 (avg:  99.56)\tAcc@5 100.00 (avg:  99.97)\tTime  1.865 (avg:  1.932)\tData  0.000 (avg:  0.065)\n",
      "Epoch: [14][ 70/282]\tLoss 3.4659e-03 (avg: 1.4811e-02)\tAcc@1 100.00 (avg:  99.56)\tAcc@5 100.00 (avg:  99.98)\tTime  1.871 (avg:  1.923)\tData  0.000 (avg:  0.056)\n",
      "Epoch: [14][ 80/282]\tLoss 7.1447e-03 (avg: 1.5305e-02)\tAcc@1 100.00 (avg:  99.59)\tAcc@5 100.00 (avg:  99.98)\tTime  1.873 (avg:  1.917)\tData  0.000 (avg:  0.049)\n",
      "Epoch: [14][ 90/282]\tLoss 4.9339e-03 (avg: 1.5296e-02)\tAcc@1 100.00 (avg:  99.55)\tAcc@5 100.00 (avg:  99.98)\tTime  1.874 (avg:  1.912)\tData  0.000 (avg:  0.044)\n",
      "Epoch: [14][100/282]\tLoss 4.8981e-03 (avg: 1.5644e-02)\tAcc@1 100.00 (avg:  99.55)\tAcc@5 100.00 (avg:  99.97)\tTime  1.859 (avg:  1.908)\tData  0.000 (avg:  0.040)\n",
      "Epoch: [14][110/282]\tLoss 2.1802e-02 (avg: 1.6056e-02)\tAcc@1  98.44 (avg:  99.55)\tAcc@5 100.00 (avg:  99.97)\tTime  1.882 (avg:  1.904)\tData  0.000 (avg:  0.036)\n",
      "Epoch: [14][120/282]\tLoss 3.1046e-03 (avg: 1.6231e-02)\tAcc@1 100.00 (avg:  99.55)\tAcc@5 100.00 (avg:  99.97)\tTime  1.875 (avg:  1.902)\tData  0.000 (avg:  0.033)\n",
      "Epoch: [14][130/282]\tLoss 2.6532e-02 (avg: 1.5954e-02)\tAcc@1 100.00 (avg:  99.56)\tAcc@5 100.00 (avg:  99.98)\tTime  1.872 (avg:  1.899)\tData  0.000 (avg:  0.031)\n",
      "Epoch: [14][140/282]\tLoss 4.2901e-03 (avg: 1.6076e-02)\tAcc@1 100.00 (avg:  99.56)\tAcc@5 100.00 (avg:  99.98)\tTime  1.856 (avg:  1.897)\tData  0.000 (avg:  0.029)\n",
      "Epoch: [14][150/282]\tLoss 1.3834e-02 (avg: 1.6107e-02)\tAcc@1 100.00 (avg:  99.54)\tAcc@5 100.00 (avg:  99.98)\tTime  1.844 (avg:  1.896)\tData  0.000 (avg:  0.027)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-74f8be96678c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# dtype=torch.float16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;32m~/few-shot-learning/few_shot/transfer.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(datadir, architecture, num_workers, epochs, start_epoch, batch_size, learning_rate, optimizer, print_freq, resume, evaluate, seed, gpu, device, dtype, distributed)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         train(train_loader, model, criterion, optimizer_ft, lr_scheduler_ft,\n\u001b[0;32m--> 273\u001b[0;31m               epoch, print_freq, _allocate_inputs)\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/few-shot-learning/few_shot/transfer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, scheduler, epoch, print_freq, allocate_inputs)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# measure elapsed time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ubuntu-7Wf190Ea/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(\n",
    "    datadir='~/data',\n",
    "    architecture='resnet50',\n",
    "    num_workers=8,\n",
    "    epochs=100,\n",
    "    start_epoch=0,\n",
    "    batch_size=64,\n",
    "    learning_rate=1e-3,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    print_freq=10,\n",
    "    resume=False,\n",
    "    evaluate=False,\n",
    "    seed=None,\n",
    "    gpu=0,\n",
    "    device=None,\n",
    "    # dtype=torch.float16\n",
    "    distributed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
